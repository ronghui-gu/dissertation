\begin{figure}
\lstinputlisting [language = C, multicols=2] {source_code/ticket_lock_example.c}
\vspace{-5pt}
\caption{Pseudocode of ticket lock example.}
\label{fig:exp:ticket_lock_example}
\vspace{-10pt}
\end{figure}

In this section, we use a concrete example (ticket locks) to explain
the high-level ideas for building certified concurrent layers.

Figure~\ref{fig:exp:ticket_lock_example} shows an example consists of three layers plus two threads
and also one scheduler object.
Each concurrent layer interface now contains also a collection
of atomic methods, each of them generate a set of events.
Layer $L_1$ consists of a list of shared atomic operations,
including the ones to access the ticket lock
data structure (\ie, two integers, 
$\now \le \ticket$),
and the ones to implement higher layers
(\ie, $\comm{f}$ and $\comm{g}$).
Layer $L_2$ provides an atomic interface
for ticket lock, implemented by $M_1$ on top of $L_1$.
Layer $L_3$ then introduces a shared object
interface $\comm{foo}$ 
protected by ticket lock.
As for the client program $P$,
we assume there are only two CPUs on the machine
and both of two threads simply invoke the primitive $\comm{foo}$.
The main verification target is to show
that both threads' invocations terminate
and generate the expected events.


We use $L[T]$ to denote the whole thread machine;
and $L[t]$ for the machine observable by thread $t$.
The behaviors of each $L[A]$ can be derived from the set of abstraction
machine indexed by the environment log $\oracle$. 
One specific run of $P$ over layer $L_1[T]$ will produce the following
shared log $l_{g1}$:
% \colorbox{Peach}{\textcolor{white}{a}}
{\small
\[
\begin{array}{l}
\ssame \cons (1.\incticket) \cons
\sdiff \cons (2.\incticket) \cons
\ssame \cons (2.\getnow) \cons
\sdiff \cons (1.\getnow) \cons
\ssame \cons (1.\holdlock) 
\\
\cons 
\sdiff \cons (2.\getnow) \cons
\sdiff \cons (1.\comm{f}) \cons
\sdiff \cons (2.\getnow) \cons
\sdiff \cons (1.\comm{g}) \cons
\ssame \cons (1.\incnow) 
\\
\cons \sdiff \cons (2.\getnow) \cons
\ssame \cons (2.\holdlock) \cons
\ssame \cons (2.\comm{f}) \cons
\ssame \cons (2.\comm{g}) \cons
\ssame \cons (2.\incnow) 
\end{array}
\]
}

We use ``$\ssame$" to denote a hardware yield to the same CPU, while
``$\sdiff$" for a yield to a different CPU.  If considering the
hardware scheduler object $hs$, both notations are abbreviations of
two switch events: switch from CPU $i$ to $hs$ (\ie, $i\switch hs$),
and then switch from $hs$ to CPU $j$ (\ie, $hs \switch j$).  For
example, starting from CPU 1, $\sdiff$ is represented as $(1\switch
hs) \cons (hs\switch 2)$.

We write $\comm{target}(l)$ to denote
the destination of the log $l$,
which can be either 1, or 2, or $hs$.
Therefore, the global log $l_{g1}$ can be written as combining the following strategies from each
individual thread and the hardware scheduler.
\begin{small}
\[
\strat{i} (l)=
\begin{cases}
i.e & \text{if } \comm{target}(l) = i \wedge
l\cons (i.e) \text{ is a prefix of } l_{g1} \\
\comm{undefined } & \text{otherwise}
\end{cases}
\]
\end{small}

At each step, depends on the destination of the current log
(\ie, $i$),
we query 
the corresponding strategy $\strat{i}$
 to get the next move of $i$.
For example, if the destination is $hs$
(\ie, the log ends with $(\any\switch hs)$),
then it is the turn for the hardware scheduler
to generate a switch event $(hs\switch \any)$.
The global log $l_{g1}$ works similarly
to the whole strategy set
(\ie, one can be constructed by the other one),
except for the fact that the strategy set is more modular.
For example, when reasoning about the CPU 1 alone,
we only need the strategies of the environment
context $\oracle_1 := \strat{hs} \bigcup \strat{2}$.

The layer interface $L_2$ introduces lock and unlock primitives.
Therefore, the underling interleaving during the lock acquiring is
hidden and the events $\acq$ and $\rel$ are generated respectively.
Thus, running $P$ over $L_2$ would produce the following shared log
$l_{g2}$:
{\small
\[
\begin{array}{l}
\ssame \cons (1.\acq) \cons
\ssame \cons (1.\comm{f}) \cons
\ssame \cons (1.\comm{g}) \cons
\ssame \cons (1.\rel) 
\\
\cons \sdiff \cons (2.\acq) \cons
\ssame \cons (2.\comm{f}) \cons
\ssame \cons (2.\comm{g}) \cons
\ssame \cons (2.\rel) 
\end{array}
\]
}

The layer interface $L_3$ introduce an atomic object interface
$\comm{foo}$, which is implemented in the critical section
protected by ticket lock.
Running $P$ over $L_3$ would produce the following shared log
$l_{g3}$:
{\small
\[
\ssame \cons (1.\comm{foo})
\cons \sdiff \cons (2.\comm{foo})
\]}

To build a refinement relation, we need to find a function from
one layer's log and environment context to another layer's log and environment.
For example, to build
$\ltyp{L_1}{R}{M_1}{L_2}$,
the intuition is to find 
a function $f_l$ to convert log
such that it captures the 
\emph{successful} events
for lock and unlock operations,
and throw away all the \emph{failed}
attempting events.
It can be defined as below:
1) it maps the $\holdlock$
and $\incnow$ events at $L_1$
to $\acq$ and $\rel$ events at $L_2$;
2) it maps  the $\incticket$ and $\getnow$ events
to empty events $\eempty$;
and 3) it merges all the empty switch events
(\eg, ``$\ssame \cons \eempty \cons \sdiff$"
is merged as ``$\sdiff$").
By this definition, we have $l_{g2} = f_l (l_{g1})$,
which can be shown as below:
{\small
\[
\begin{array}{l}
\mysout
{\ssame \cons (1.\incticket) \cons
\sdiff \cons (2.\incticket) \cons
\ssame \cons (2.\getnow) \cons
\sdiff \cons (1.\getnow) \cons
}
\ssame \cons (1.\cancel{\holdlock}/\acq) 
\\
\mysout
{\cons 
\sdiff \cons (2.\getnow) \cons
\sdiff 
} 
\ssame \cons (1.\comm{f}) \cons
\mysout
{\sdiff \cons (2.\getnow) \cons
\sdiff
}
\ssame \cons (1.\comm{g}) \cons
\ssame \cons (1.\cancel{\incnow}/\rel) 
\\
\cons \sdiff 
\mysout
{\cons (2.\getnow) \cons
\ssame 
}
\cons (2.\cancel{\holdlock}/\acq) \cons
\ssame \cons (2.\comm{f}) \cons
\ssame \cons (2.\comm{g}) \cons
\ssame \cons (2.\cancel{\incnow}/\rel) 
\end{array}
\]
}

Since the strategy set is built from the global log, 
we can build a function $f_{\strat{}}$ for the strategy set
in terms of $f_l$:

\begin{small}
\[
f_{\strat{}}(\strat{i}) (l')=
\begin{cases}
i.e' & \text{if } 
\exists l, f_l(l) = l' \wedge \strat{i}(l) = i.e\\
&\qquad\ \wedge f_l(l\cons(i.e)) = l' \cons (i.e') \\
\comm{undefined } & \text{otherwise}
\end{cases}
\]
\end{small}

The intuition of $f_{\strat{}}(\strat{i})$ is as below:
since many events are mapped to $\eempty$
at $L_2$,
including the $(i\switch hs)$ event that is merged as
an empty switch,
$f_{\strat{}}(\strat{i}) (l')$
has to keep querying the strategy $\strat{i}$
until returning an non-empty event from $i$ at $L_2$.
Thus, the function $f_{\oracle}$
for the environment context
$\oracle$ can also be constructed using $f_{\strat{}}$.
\ronghui{Do I need to show some examples
for $f_{\strat{}}(\strat{i})$?
}

For example,
let $l:=\ssame \cons (1.\incticket) \cons
\sdiff \cons (2.\incticket) \cons
\ssame \cons (2.\getnow) \cons
\sdiff \cons (1.\getnow) \cons
\ssame$,
since $\strat{1} (l) = 1.\holdlock$
and $f_l(l) = \ssame$,
we have that
\[
f_{\strat{}}(\strat{1}) (\ssame) =1.\holdlock
\]

\ronghui{The following lemma is not useful at all.
I just want to clarify that $f_{\strat{}}$ is well-defined.}
\begin{lemma}
$f_{\strat{}}$ is well-defined.
\proof
If $f_{\strat{}}$ is not well-defined.
We know that there exists a $l'$,
such that the value of $f_{\strat{}}(\strat{i}) (l')$
is not decidable.
Thus, there exists $l_0 \neq l_1$,
such that $f_l(l_0) = f_l(l_1) = l'
\wedge \strat{i}(l_0) = i.e_0
\wedge \strat{i}(l_1) = i.e_1
\wedge f_l(l_0\cons(i.e_0)) = l' \cons (i.e_0')
\wedge f_l(l_1\cons(i.e_1)) = l' \cons (i.e_1')
\wedge e_0' \neq e_1'$.
By the definition of $\strat{i}$,
we know both $l_0\cons(i.e_0)$ and $l_1\cons(i.e_1)$
is a prefix of $l_{g1}$.
Then, we assume $l_0\cons(i.e_0)$ is a prefix 
of $l_1$.
Thus, $f_l(l_1\cons(i.e_1))
= f_l(l_0\cons(i.e_0) \cons l_t \cons(i.e_1))
= l' \cons (i.e_0') \cons f_l(l_t) \cons (i.e_1')
\neq l' \cons (i.e_1')$.
\qed
\end{lemma}

Reasoning about a concrete strategy is simple,
but the verification of concurrent programs  cannot assume 
such a specific environment context.
Instead, it can impose a ``rely'' condition, that is, all the environment contexts
must satisfy a few invariants. 
Thus, to verify the program running on CPU1,
we have to show that
the implementation meets the specification
for all possible environment context $\oracle_1$
that satisfies the invariants.

Take the lock acquire as an example.
We have to show
that the implementation
(which keeps checking 
the value of $\comm{now}$ until 
it is equal to the previous $\comm{ticket}$)
meets an atomic specification.
This requires a starvation-freedom proof
for the ticket lock algorithm.
For CPU1,
the ``reply" conditions it can assume
for the environment context $\oracle_1$
are as below:
\begin{itemize}
\itemsep0em
\item ($\comm{INV}_{hs}$).  $\strat{hs}$ is \emph{fair},
which means that, for any CPU $i$,
the gap between two $(hs \switch i)$ events
in the log
is less than $m$.
\item ($\comm{INV}_{2}$).
$\strat{2}$ will eventually release
the its held lock, which means that
the events generated by CPU2 is
 less than $n$ between $(2.\holdlock)$
and $(2.\incnow)$.
\end{itemize}

Therefore, we have that, when CPU1 acquires the lock,
the loop iteration (\cf line15 in Fig~\ref{fig:exp:ticket_lock_example})
is less than $n \times m$.
Because CPU2 can generate at most $n$
events before releasing the lock
and $\strat{hs}$ is fair to CPU2.

One interesting aspect of our layered approach is that,
we do not need to prove that CPU1
 \emph{guarantees} to release the lock within $n$ steps at layer $L_1$ immediately.  
 We can delay this guarantee proof to layer $L_2$,
 where each lock acquire is paired with a lock release.
 Two certified layers are are allowed to compose 
 only if their own guarantees can imply 
 others' rely condition.
