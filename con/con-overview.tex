\section{Informal Development}
\label{sec:informal}

In this section, we give an overview of a few high-level ideas on how
we build certified concurrent layers. 

Like a sequential layer~\cite{dscal15}, each concurrent layer can also
contain thread-private abstract states (refined from the concrete
thread-local in-memory data) and related abstract primitives. However,
the data shared by multiple threads are not represented as abstract
states. Instead, each method call to a shared atomic object is
recorded as an observable event and is appended to the end of a shared
global log. For each shared object, we define a {\em replay} function
that can reconstruct the current shared state from the current global
log. Thus, all shared objects are represented as a single sequence of
logged events with appropriate replay functions.

With concurrency, the machine semantics for each layer (e.g.,
$\sem{L}{\cdot}$) is no longer deterministic: for each scheduler
strategy ($\strat{hs}$), it may generate a different global
log. To prove the simulation $\sem{L'}{P\oplus{}M} \leq_R \sem{L}{P}$,
for each scheduler strategy $\strat{hs}$, if running $P\oplus{}M$ on
machine $L'$ with $\strat{hs}$ produces a global log $l$, we must find
another scheduler strategy $\stratp{hs}$ such that running $P$ on
machine $L$ under $\stratp{hs}$ would generate a global log $l'$ that
is related to $l$ via the simulation relation $R$. We will actually
construct a {\em function} that will map $l$ and $\strat{hs}$ into
$l'$ and $\stratp{hs}$. Of course, the simulation relation $R$ over
thread-private states might still be a relation~\cite{dscal15}.

\paragraph{An example of concurrent layers}
The example in Figure~\ref{fig:exp:ticket_lock_example} contains a
client program $P$ which has two threads running on two different
CPUs; each thread makes one call to the atomic primitive $\comm{foo}$
provided by the layer interface $L_3$.

Concurrent object module $M_2$ implements the layer interface $L_3$
but it is built on top of $L_2$.  The $\comm{foo}$ method calls two
atomic primitives $f$ and $g$ in a critical section protected by a
ticket lock~\cite{mcs91}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\lstinputlisting [language = C, multicols=2] {source_code/ticket_lock_example.c}
%\vspace{-5pt}
\caption{Building certified concurrent layers over a ticket lock}
\label{fig:exp:ticket_lock_example}
\vspace{-10pt}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The ticket-lock module $M_1$ is built on top of $L_1$ and it
implements $L_2$. Even though the implementation of a ticket lock
contains two shared integer value fields: $\comm{ticket}$ and
$\comm{now}$ (where $\comm{now} \leq \comm{ticket}$ always holds), the
interface $L_1$ only provides the atomic primitives such as
fetch-and-incrementing the $\comm{ticket}$ value, getting the current
$\comm{now}$ value, holding the lock (if the $\comm{now}$ value is
equal to the $\comm{ticket}$ value), and incrementing the $\comm{now}$
value (to release the lock). The current $\comm{ticket}$ and
$\comm{now}$ values can be reconstructed by replaying the global log
(for the $L_1$ machine).  $L_1$ also provides the atomic $\comm{f}$
and $\comm{g}$ events which are later passed on to $L_2$.

\paragraph{Strategy, environment context, and layer simulation}
Our goal is to show that for each run of $P\oplus{}M_2\oplus{}M_1$
over $L_1$, we can find another run of $P$ over $L_3$ so that the
global logs produced by both runs are related.
To show how we accomplish this, here is
a global log $l_{g1}$ produced from  
a specific run of $P\oplus{}M_2\oplus{}M_1$ over $L_1$.

\vspace*{-1ex}
% \colorbox{Peach}{\textcolor{white}{a}}
\begin{small}
\[
\begin{array}{l}
\ssame \cons (1.\incticket) \cons
\sdiff \cons (2.\incticket) \cons
\ssame \cons (2.\getnow) \cons
\sdiff \cons (1.\getnow) \cons
\ssame \cons (1.\holdlock) 
\\
\cons 
\sdiff \cons (2.\getnow) \cons
\sdiff \cons (1.\comm{f}) \cons
\sdiff \cons (2.\getnow) \cons
\sdiff \cons (1.\comm{g}) \cons
\ssame \cons (1.\incnow) 
\\
\cons \sdiff \cons (2.\getnow) \cons
\ssame \cons (2.\holdlock) \cons
\ssame \cons (2.\comm{f}) \cons
\ssame \cons (2.\comm{g}) \cons
\ssame \cons (2.\incnow) 
\end{array}
\]
\end{small}%

Throughout this paper, we assume that all programs always
start from CPU 1, and before each CPU executes an atomic primitive,
it always yields to the hardware scheduler ($hs$).
We use $\ssame$ to denote a hardware yield to the same CPU,
and $\sdiff$ for a yield to a different CPU; each such symbol
is actually an abbreviation of two consecutive switch events: switch
from CPU $i$ to $hs$ (\ie, $i\switch{}hs$), and then switch from $hs$
to CPU $j$ (\ie, $hs \switch j$).  For example, starting from CPU 1,
$\sdiff$ is an abbreviation of $(1\switch{}hs) \cons (hs\switch 2)$.

We define $\comm{target}(l)$ as the switching destination of the last event in
the log $l$, which can be either 1, 2, or $hs$. The above run,
which produced the global log $l_{g1}$, can be viewed as combining
the following {\em strategies} defined for each CPU and $hs$:

\vspace*{-1ex}
\begin{small}
\[
\strat{j} (l)=
\begin{cases}
  j.e & \text{if } (\comm{target}(l) = j) ~~\wedge \\
      & ~~~~~(l\cons (j.e)) |_{j,hs} \text{ is a prefix of } (l_{g1} |_{j,hs}) \\
\comm{undefined } & \text{otherwise}
\end{cases}
\]
\end{small}%

\noindent{}Here, $l |_{j,hs}$ only keeps those events in $l$ that are
related to participants $j$ and $hs$.  For the hardware scheduler's
strategy $\strat{hs}$, this filtering essentially means that
regardless how the CPUs (or threads) are going to play in the interim,
$hs$'s moves will always follow $l_{g1}$.  Because $\strat{hs}$
defines how switching between different CPUs is done, when we define
each CPU's strategy, we filter out other CPUs' events but still keep
those events related to $hs$.

At each step, depending on the destination ($j$) of the current log
($l$), we can query the corresponding strategy $\strat{j}(l)$ to get the
next move for $j$.  For example, if the destination is $hs$, that is,
the log ends with $(\any\switch hs)$, then it is the
hardware scheduler's turn to generate a switch event $(hs\switch \any)$.

These strategies also form a nice decomposition of the global log
$l_{g1}$. To reason about CPU 1 alone, we only need to construct
its environment context $\oracle_1 := \strat{hs} \bigcup \strat{2}$.

The layer interface $L_2$ introduces the $\acq$ and $\rel$ primitives
which trigger events $\acq$ and $\rel$ respectively. Running
$P\oplus{}M_2$ over $L_2$ could produce the following shared log $l_{g2}$:

\vspace*{-1ex}
\begin{small}
\[
\begin{array}{l}
\ssame \cons (1.\acq) \cons
\ssame \cons (1.\comm{f}) \cons
\ssame \cons (1.\comm{g}) \cons
\ssame \cons (1.\rel) 
\\
\cons \sdiff \cons (2.\acq) \cons
\ssame \cons (2.\comm{f}) \cons
\ssame \cons (2.\comm{g}) \cons
\ssame \cons (2.\rel) 
\end{array}
\]
\vspace{-5pt}
\end{small}%

The layer interface $L_3$ introduces the atomic $\comm{foo}$
primitive. Running $P$ over $L_3$ could produce the following shared log
$l_{g3}$:
\vspace*{-1ex}
\begin{small}
\[
\ssame \cons (1.\comm{foo})
\cons \sdiff \cons (2.\comm{foo})
\]
\vspace{-7pt}
\end{small}%

To build a simulation, we want to define a function mapping one
layer's log and environment context into those of another layer.  For
example, the function $f_l$, mapping a log over $L_1$ into one over
$L_2$, can be defined as follows: (1) it maps the $\holdlock$ and
$\incnow$ events in $L_1$ to $\acq$ and $\rel$ events in $L_2$; (2) it
drops the $\incticket$ and $\getnow$ events; 
and (3) it merges all the adjacent switch symbols (\eg,
$\ssame \cons \sdiff$ is merged into $\sdiff$).
The following shows that $l_{g2} = f_l (l_{g1})$ is true:

\vspace*{-1ex}
\begin{small}
\[
\begin{array}{l}
\hspace*{-1em}\mysout
{\ssame \cons (1.\incticket) \cons
\sdiff \cons (2.\incticket) \cons
\ssame \cons (2.\getnow) \cons
\sdiff \cons (1.\getnow) \cons
}
\ssame \cons (1.\cancel{\holdlock}/\acq) 
\\
\hspace*{-1em}\mysout
{\cons 
\sdiff \cons (2.\getnow) \cons
\sdiff 
} 
\ssame \cons (1.\comm{f}) \cons
\mysout
{\sdiff \cons (2.\getnow) \cons
\sdiff
}
\ssame \cons (1.\comm{g}) \cons
\ssame \cons (1.\cancel{\incnow}/\rel) 
\\
\hspace*{-1em}\cons \sdiff 
\mysout
{\cons (2.\getnow) \cons
\ssame 
}
\cons (2.\cancel{\holdlock}/\acq) \cons
\ssame \cons (2.\comm{f}) \cons
\ssame \cons (2.\comm{g}) \cons
\ssame \cons (2.\cancel{\incnow}/\rel) 
\end{array}
\]
\end{small}

From $f_l$, we can construct a function $f_{\strat{}}$
that maps each strategy $\strat{j}$ for $L_1$ into one for $L_2$:

\vspace*{-1ex}
\begin{small}
\[ 
f_{\strat{}}(\strat{j}) (l'')=
\begin{cases}
j.e' & \text{if } 
\exists l', f_l(l') = l'' \wedge \strat{j}(l') = j.e\\
&\qquad\ \wedge f_l(l'\cons(j.e)) = l'' \cons (j.e') \\
\comm{undefined } & \text{otherwise}
\end{cases}
\]
\end{small}

Here, since many $L_1$ events are dropped in $L_2$,
the $L_2$ strategy $f_{\strat{}}(\strat{j})$ for $j$
has to keep querying $\strat{j}$ until
it also returns an event from $j$ at $L_2$.  For example, let $l'$ be
$\ssame \cons (1.\incticket) \cons \sdiff \cons (2.\incticket) \cons
\ssame \cons (2.\getnow) \cons \sdiff \cons (1.\getnow) \cons \ssame$,
since $\strat{1} (l') = 1.\holdlock$ and $f_l(l') = \ssame$, we have
$f_{\strat{}}(\strat{1}) (\ssame) =1.\holdlock$.

Finally, from $f_{\strat{}}$ we can construct the function
$f_{\oracle}$ which will map each environment context $\oracle$ for
$L_1$ into one for $L_2$.

\paragraph{Layer verification and composition}
Reasoning about a concrete strategy is simple, but when we verify
a concurrent module, we cannot assume such a specific environment context.
Instead, to verify
a layer running on CPU~$i$, we have to show that its implementation
meets its specification for all possible environment contexts
$\oracle_i$ that satisfy its ``rely'' invariants.

For example, to show that $\ltyp{L_1[1]}{R}{M_1}{L_2[1]}$, we must
show that the implementation of $\acq$ meets its specification.
This requires us to prove the starvation-freedom of the ticket
lock algorithm. To do so, we can impose the following rely conditions
over $\oracle_1$:
%%%%%%
\begin{itemize} \itemsep 0pt
\item ($\comm{INV}_{hs}$):  $\strat{hs}$ is \emph{fair}, that is,
  for any CPU $i$, the gap between two $(hs \switch i)$ events
  in the log is less than some constant $m$.
%%%%%%%
\item ($\comm{INV}_{2}$):  $\strat{2}$ will eventually release the
  lock it held, that is, the number of events generated by CPU~2
  between $(2.\holdlock)$ and $(2.\incnow)$   is less
  than some constant $n$ .
\end{itemize}
%%%%
Therefore, when CPU~1 acquires the lock, the loop iteration (\cf
line 17 in Fig~\ref{fig:exp:ticket_lock_example}) is bound by
$n \times m$, because CPU~2 can generate at most $n$ events before
releasing the lock and $\strat{hs}$ is fair to CPU~2.

Interestingly, we do not need
to prove that CPU~1 \emph{guarantees} to release the lock within $n$
steps in machine $L_2[1]$
when we prove $\ltyp{L_1[1]}{R}{M_1}{L_2[1]}$.  We can restore
this guarantee proof when we prove $\ltyp{L_2[1]}{R}{M_2}{L_3[1]}$
since clearly, each call to $\acq$ in $M_2$ is followed by a call to
$\rel$ within three steps.

Two certified layers are allowed to compose only if each one's guarantee
implies the other's rely. We cannot parallel-compose
$\ltyp{L_1[1]}{R}{M_1}{L_2[1]}$ and $\ltyp{L_1[2]}{R}{M_1}{L_2[2]}$;
but we can first get $\ltyp{L_1[1]}{R}{M_1\oplus{}M_2}{L_2[1]}$ and
$\ltyp{L_1[2]}{R}{M_1\oplus{}M_2}{L_2[2]}$, and then compose these to
get $\ltyp{L_1[T]}{R}{M_1\oplus{}M_2}{L_2[T]}$.






