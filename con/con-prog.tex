\section{Layered Concurrent Programming}
\label{sec:prog}

\ignore{
\paragraph{outline} 1) C-level vs assembly-level programming
2) layer refinement for composing multiple events?
3) spinlocks (ticket lock, MCS lock)
4)thread management
5) queuing locks
6) starvation-free condition variable
}


In this section,\ignore{we instantiate our framework with a
C-like language ClightX and an assembly level language LAsm,
and we introduce the concurrent layer interfaces for
a single active CPU.
To demonstrate the modularity and practicality of our framework
for concurrent program reasoning,}
we show how to verify spinlock implementations, shared queues protected by spinlocks,
thread scheduling primitives, and a queuing lock,
using concurrent abstraction layers.
All layers are built upon the single-core machine $\LAsm{(L(c,\oracle))}$.


\paragraph{Scheduler primitives and multi-thread composition}
It is common for multi-threaded programs to perform explicit synchronization
of threads by calling scheduler primitives, e.g., $\yield$, $\sleep$, and $\wakeup$.
Verification of such concurrent programs is extremely challenging.
Previous work either directly models the abstract scheduler primitives at a high level
(e.g., simple switch in the thread ID~\cite{xu16}),
or verifies the scheduler functions with a low level small-step semantics
(e.g., saving and restoring the register set) \cite{dscal15}.
Both approaches have severe limitations. The first approach provides no formal connection
between the specification and underlying C and assembly implementation of those
scheduler functions. In the second approach, the specifications are too low level to
be useful in verifying the actual programs calling these primitives. Furthermore,
some portion of scheduler functionality is implemented in assembly (e.g., context switch).
Thus the semantics does not satisfy the C calling convention, meaning that it 
is impossible to reason about programs calling these assembly functions at the C level.

In this example, we build concurrent layers for the assembly part
of a scheduler in a small-step manner, but later lift the specifications
to big-step ones satisfying the C calling conventions. 
This allows us to perform \emph{thread-local} reasoning of programs
at the C level, where the proved properties of each thread can be linked formally
to obtain a global claim about the whole set of threads running on a processor.
To the best of our knowledge, this is the first attempt to support modular verification
of multi-threaded applications with explicit synchronization using verified
low level scheduler primitives.

\vspace{3pt}
\noindent\textbf{Step 1 (assembly-level specification $L_5$)} 
Figure~\ref{fig:exp:sched} shows the implementation
of selected scheduling functions.
The $\yield$ function first polls a pending
thread from the per-CPU pending queue
(\ie, $\comm{pendq}(c)$),
then selects the next running thread
from the CPU-local ready queue
(\ie, $\comm{rdq}(c)$),
and finally switches the kernel context.
The $\sleep$ function is similar: it
puts the current running thread
on the sleeping queue (\ie, $\comm{slpq}(q)$) and
then context switches.
The $\wakeup$ function moves the head of the sleeping queue
into the corresponding CPU's pending queue.
The context switch function $\mathsf{cswitch}$
saves the current thread's kernel context (including the 
\emph{stack pointer}),
and loads the context of the target thread.
This function $\mathsf{cswitch}$ can only be implemented at the assembly level,
and its specification does not satisfy the C calling convention.
To verify these low level scheduler functions, we introduce an
assembly-style concurrent layer interface $L_5$.
\begin{figure}
\lstinputlisting [language = C, multicols=2] {source_code/scheduling.c}
\vspace{-10pt}
\caption{Pseudocode of scheduling implementation.}
\label{fig:exp:sched}
\vspace{-10pt}
\end{figure}


At layer $L_5$, we introduce three new events
$c.\yield$, $c.\sleep(i)$, and $c.\wakeup(i)$,
which map to $L_4$'s events
$c.\deq(\comm{pendq}(c))$,
$c.\enq(\comm{slpq}(i))$,
and $c.\enq(\comm{pendq}(c))$, respectively.
Since the mapping is one-to-one, the transformation functions for
the log ($f_{l4}$) and environment context ($f_{\oracle4}$)
can be defined trivially.
The specifications of $\yield$ and $\sleep$
are defined as follows:
\begin{small}
\begin{mathpar}
\inferrule{
l_0 = l \cons \oracle (l) \\
\replay_{\comm{sched}} (l_0, c) = (tid, tdqp, tcbp) \\
a' = a\set{\comm{kctxt}(tid) : \regs[\comm{ra},
\comm{ebp}, \comm{ebx}, \comm{esi}, \comm{edi}, \comm{esp}]} \\
l' = l_0 \cons c.\yield/c.\sleep(i) \\
\replay_{\comm{sched}} (l', c) = (rtid, \any, \any) \\
\regs' = \regs\leftarrow a.\comm{kctxt}(rtid)  
}{
 \oracle, c\vdash_{\comm{Asm}}  \spec_{\yield/\sleep}([]/[i],\regs, m, a, l,\any, \regs',  m, a', l')
}
\end{mathpar}
\end{small}%
The abstract states $\comm{tid}$,
$\comm{tdqp}$, and $\comm{tcbp}$
are hidden at $L_5$, since they can always be reconstructed
by the replay function $\replay_{\comm{sched}}$ given the current log.
The replay function $\replay_{\comm{sched}}$
is defined inductively.
Here we only present the case for the $\sleep$ event:
\begin{small}
\begin{mathpar}
\inferrule{
\replay_{\comm{sched}} (l, c) = (tid, tdqp, tcbp) \\
\comm{tdqp} (\comm{rdq}(c)) = r\cons q \\
\comm{tdqp} (\comm{slpq}(i)) = q' \\
\comm{tdqp}'  = \comm{tdqp}
\set{\comm{rdq}(c): q}
\set{\comm{slpq}(i):q'\cons tid}\\
\comm{tcbp}'  = \comm{tcbp}
\set{tid: \comm{SLEEP}}
\set{r:\comm{RUN}}
}{
\replay_{\comm{sched}} (l \cons c.\sleep (i), c) = (r, tdqp', tcbp') 
}
\end{mathpar}
\end{small}%
\noindent\textbf{Step 2 (multi-threaded machine $\TAsm$)} 
The  layer interface $L_5$ is defined for the whole
set of threads for CPU $c$ and does not support thread-local reasoning.
Ideally, we would like to reason about each thread running on the CPU 
locally, and later formally combine the reasoning to obtain a global
property for the full set of threads.
To support this, we need a machine model that gives semantics to
a partially-composed set of threads.

Let $T_c$ denote the whole set of threads running over CPU $c$.
From $\LAsm(L_5(c,\oracle))$, we construct a new 
multi-threaded \emph{partial} machine $\TAsm$,
and instantiate it with a layer interface $L_6$.
The result machine 
$\TAsm(L_6(c), A)\langle \oracle \rangle$ is 
parameterized over an active thread set $A \subseteq T_c$,
and can be instantiated into a regular machine for
an environment context $\oracle$.
The machine state of $\TAsm$ is defined as $s:=(\tid, f_\regs, m, f_a, l)$.
Here, $\tid$ is the current thread ID, and
$f_\regs$ and $f_a$ are partial functions
from IDs of threads in $A$ to a register set $\regs$
and a per-thread abstract state $a$, respectively (\ie,
we divide the register set and the abstract state
into separate ones for each thread).
The relation between abstract states
can be easily defined, but the relation of the register set between $L_5$ and $L_6$ is non-trivial.
For the currently-running thread, its local register set ($s_6.f_\regs(s_6.\tid)$) is equal
to the register set of $L_5$ ($s_5.\regs$).
For other threads of $L_6$, the local register set is equal
to the corresponding saved kernel context of $s_5$ for the registers
$[\comm{ra}, \comm{ebp}, \comm{ebx}, \comm{esi}, \comm{edi}, \comm{esp}]$.
In other words, the register set is decomposed in a way such that the $\regs$ of the
currently-running thread is equal to the machine's register set, while the $\regs$ of
other threads is equal to the corresponding kernel context saved by context switch.

\ignore{
However, $m$ is using
the CompCert memory model \cite{leroy08},
which is not compositional \ronghui{reference here?Tahina?}.
We introduce a new \emph{algebraic memory
model} to make the CompCert memory model
modular (\cf Sec.~\ref{sec:comp} for more details).
Two machines are composable only if they have the same
logical log $l$.
}

For instructions and primitives that do not change the current thread
ID, their semantics are lifted from $L_5$ to $L_6$
by instead operating on the state $(f_\regs(\tid), m, f_a(\tid), l)$.
The scheduling functions (which may change the thread ID to a thread outside of $A$)
are part of the definition of $\TAsm$
and may trigger environment steps by generating events
that will switch control to a thread outside of $A$.
For instance,
the $\yield$ operation of $\TAsm$
will generate a $c.\yield$ event that will switch control to the next thread
and set the machine's $\tid$ accordingly.
If the new thread is in $A$,
then the $\TAsm$ machine will simply keep running local steps of the new thread.
If the new thread is outside of $A$,
then the machine will take environment steps
until the log indicates that control switches back to  $A$.

When $A$ is the entire thread set $T_c$ of core $c$,
it will never switch to environment threads and
we have the following refinement:
\begin{lemma}{\small
$\forall \oracle\ ,~
\LAsm(L_5(c,\oracle)) 
\refines
\TAsm(L_6(c), T_c)\langle \oracle \rangle$}%
\label{thread_composition}
\end{lemma}

However,
the partial machine $\TAsm$ can also be decomposed using the linking operator $\Join$,
which enables the thread-local reasoning:
\begin{lemma}
{\small
$
\TAsm(L_6(c), T_c)
\Refrel_\id
\bigJoin_{t \in T_c}
\TAsm(L_6(c), \{t\})
$}
\label{thread_compose}
\end{lemma}

%-----------------------------
\ignore{
For scheduling functions (which may change the thread ID to one for a thread not in $A$),
it may trigger the environment step by querying the environment
context $\oracle_T$, which capture the behavior of \emph{inactive} threads (\ie, the threads in $T_c - A$).

We define the specifications of scheduling functions using $\oracle_T$.
For example, the $\yield$ primitive at $L_6$ is specified as:
\begin{small}
\begin{mathpar}
\inferrule{
l_0 = l \cons \oracle (l) \\
(l', \tid') =  \comm{yield\_back}
(A, \oracle_T, l_0 \cons c.\yield) \\
f_\regs' = f_\regs\set{\tid': 
\text{undefined value except for }[\comm{ra},
\comm{ebp}, \comm{ebx}, \comm{esi}, \comm{edi}, \comm{esp}]}
}{
 A, \oracle_T, \oracle, c\vdash_{\comm{Asm}}  \spec_{\yield'}([],\tid,f_\regs, m, f_a, l,\any, \tid', f_\regs',  m, f_a, l')
}
\end{mathpar}
\end{small}%

Note that $\yield$ changes the $\tid$ to $\tid'$.
After that, the execution operates on
the state $f_\regs'(\tid')$ and $f_a(\tid')$.
When $\tid'$ is different from $\tid$, this simulates the behavior of context switch
within the active thread set $A$. 
If the active thread set $A$ is $T_c$, we have:
}

\ignore{
If the active thread set $A$ is the whole
thread set $T_c$, we have:

Then, we can prove the simulation
relation:
\begin{lemma}[$\LAsm$ refines $\TAsm$]
\label{thread_composition}
{\small
\[
\forall \oracle,~
\LAsm(L_5(c,\oracle)) 
\refines
\TAsm(L_6(c,\oracle, T_c, \any))
\]}%
\end{lemma}



\begin{lemma}[CPU-local machine refines multi-thread machine]
{\small
\[
\forall M~ \oracle, 
\sem{ }{M}L_5(c,\oracle) \Refrel_{R_5} 
\sem{}{M}L_6(T_c, \oracle)
\]}
\label{whole_thread_composition}
\end{lemma}}

\ignore{
\textbf{Proof sketch}:
For whole thread set,
the environment context only carries
the information of the context CPUs.
Thus, $\oracle_{T_c} = \oracle$.
For the simulation relation $R_5(s_5,s_6)$, 
the only non-trivial part is the relation
for register set function $s_6.\regs p$.
For the current thread,
$s_6.\regs p(s_6.\tid)= s_5.\regs$.
For other threads,
the register set of $s_6$ is equal
to the kernel context of $s_5$
for the register list
$[\comm{ra},
\comm{ebp}, \comm{ebx}, \comm{esi}, \comm{edi}, \comm{esp}]$.
\ignore{
which is defined as:
1) ;
and 2)$\forall i \neq s_6.\tid,
s_6.\regs p(i)= s_5.a.\comm{kctxt}$.}
}
%-----------------------------

\noindent\textbf{Step 3 (thread-local layer interface $L_7$)} 
Finally, we introduce a per-thread layer interface $L_7$, which is parameterized
over a single active thread $t\in T_c$.
Thus, $\yield$ always yields back to itself,
and there is no longer any ``internal'' low level context switch among active threads.
Thus, we obtain the following big-step specification of $\yield$ that actually
satisfies the C calling convention:
\begin{small}
\begin{mathpar}
\inferrule{
l_0 = l \cons \oracle (l)\\
(l', \tid) =  \comm{yield\_back}
(\tid, \oracle, l_0 \cons c.\yield)
}{
 \tid, \oracle, c, \oracle \vdash  \spec_{\cyield}([],\regs, m, a, l,\any, \regs,  m, a, l')
}
\end{mathpar}
\end{small}%
Here, the auxiliary function $\comm{yield\_back}$ 
specifies the behavior of repeatedly querying the environment context
$\oracle$ until the control flow yields back to the thread of interest $\tid$.
It appends all the events triggered by the inactive threads to the log.
To prove termination-sensitive contextual refinement,
we prove that $\comm{yield\_back}$ actually terminates,
by showing that the scheduler is \emph{fair} and every running
thread gives up the CPU within a finite number of steps.

On top of this thread-local machine $\LAsm(L_7(c, t, \oracle))$,
we can reason about a thread's program 
locally at the C level by building per-thread layers.
We show that $L_6$ for a single thread is refined $L_7$:
{\small
\[ \TAsm(L_6(c), \{t\})\langle \oracle \rangle \Refrel \LAsm(L_7(c, t, \oracle)) \]
}%

% ------------------------------------------------------------------
% Let's not talk about linking partial machines here
\ignore{
By Lemma~\ref{lemma:mono},
per-thread layers can be composed using
``$\Join$", and propagated down to the $L_6$ machine.
Once the layers are composed for the full thread set $T_c$, we can apply Lemma~\ref{thread_composition}
to transfer the guarantee down to $L_5$
and link with per-CPU layers.
}
% ------------------------------------------------------------------

\paragraph{Queuing Lock} is an algorithm whereby waiting threads are put to sleep,
so that busy waiting is avoided.
Verification of this complex locking algorithm is particularly
challenging since its C implementation utilizes both
spinlocks and low level scheduler primitives ($\sleep$ and $\wakeup$).
In our framework, a queuing lock implementation is verified
by building multiple layer interfaces on top of $L_7$.

\ignore{
We first introduce two atomic operations (using $\comm{CAS}$)
that set and clear the busy bit of the lock.
Then we prove that the implementations
of the lock and unlock operations
satisfy their atomic specifications
(which generate single $\comm{acq\_q}$ and $\comm{rel\_q}$ events, respectively).
This is achieved by proving a simulation between layer interfaces together
with starvation-freedom, using a strategy similar to verification of
the ticket lock implementation.
}

\ignore{

 is a general
lock algorithm that 
allows sleeping for the lock, instead of busy waiting.
Since queuing lock
relies on the spinlocks and thread scheduling
and is implemented at C-level
(\cf Fig.~\ref{fig:exp:queue_lock}),
it is hard to reason about
and has never been verified in previous works.

In our framework, queuing lock can be easily verified
based on $L_7$.
We first introduce two atomic operations
to set the busy bit if the lock is free (\ie,
$\comm{CAS\_qlock}$, implemented
using $\comm{CAS}$),
and to clear the busy bit (\ie, $\comm{clear\_qlock}$).
Then, we prove the implementation 
of lock and unlock operations
satisfy the atomic specifications
(\ie, $\comm{acq\_q}$ and $\comm{rel\_q}$ events)
by showing the simulation relation
and the starvation-freedom.
The verification details are similar to the ticket lock.

\begin{figure}
\lstinputlisting [language = C, multicols=2] {source_code/queue_lock.c}
\vspace{-5pt}
\caption{Pseudocode of queuing lock implementation.}
\label{fig:exp:queue_lock}
\vspace{-10pt}
\end{figure}

}
