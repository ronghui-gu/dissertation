
\section{Implementation and Deployment}
\label{sec:eval:impl}
%\section{Implementation}
%\label{sec:imp}

\paragraph{Coq implementation}

After we finished the verification of different OS kernels presented
here, we have employed an exhaustive clean-up process to improve our
layered specification and verification framework.  Our initial Coq
implementation required verifying the contextual version of the
{\em implements} relation at each layer.  While such layer refinement
proofs followed some fixed patterns, the proof process heavily relied
on copying and pasting the existing templates and filling in the
missing proof holes.  The copy and paste approach also brought some
code and proof duplication.  In the new implementation, we instead
verify the per-primitive {\em implements} relation and then rely on the
soundness theorem of the layer calculus to turn this relation into the
contextual version. The contextual correctness property is derived
from the monotonicity of the client context in the carrier language.

We have also implemented more automation tactic libraries to further
ease the task of the verification. We are able to automate the majority of
tasks in the code verification and refinement proofs by extensively
applying these tactics. For the code verification, these tactics are
used for automatic definition unfolding, rewriting of terms, proving
that primitive calls never fault, verification condition generation,
and other first-order theorem proving to discharge the verification
conditions.  For the refinement relation, we developed a decision
procedure that automatically applies the layer calculus rules to split
the layer refinement into per-function forward simulations.  As for
the per-function forward simulation, getter-setter functions and
pass-through primitives are proved completely by tactic automations.
In the future, we are also interested in implementing horizontal
composition with framing to substitute the pass-through primitives.
We also built some extra libraries to prove x86 addressing modes and
the specification properties required by the layer calculus and
CompCertX.  Furthermore, we have extended the arithmetic
tactic \texttt{omega} with integer division and modulus.  Coq's
Ltac language is untyped, thus fixing a formal layer calculus helped a
lot in stabilizing these tactic libraries.

In our first approach, we tried to bundle the abstract data together
with the invariants on them using dependent types. This made the
automation of proofs more difficult as every time a new instance is
constructed, the framework requires us to explicitly construct a proof
that the new data satisfies the invariants. In our new approach, we
handle the invariants separately, and thus the invariants no longer
appear in the semantics of the primitives nor in the verification of
the programs. Then, we prove the layer interface invariant
preservation once and for all by showing that the initial abstract
data satisfies the invariants and all the semantics of the primitives
preserve the invariants. This proof makes sure that the layer
interface invariants are preserved during any execution, for all
programs (including the context) running on top of the layer
interface.


\paragraph{Proof effort}
With the help of the layer calculus and automation libraries
introduced in the new implementation, we successfully reduced the work
of adding one new layer from 4,000 lines of Coq code to 500 lines on
average.  The rough compilation time for a layer was reduced from a
few minutes to less than a minute.

The verification effort roughly falls into three categories: layer
design with specification and invariants, refinement proofs between
the layers, and verification of C and assembly code with respect to
the specifications. The time needed for each of the categories depends
largely on the layer.  For instance, at the boundary of physical and
virtual memory management ({$L_\code{MPTIntro}$}), almost all effort
is in the refinement proof, due to the proof for the refinement between
two completely different memory models. More effort went into the
refinement proof when we introduced the Intel \emph{virtual machine
memory model}, where we proved the refinement between the concrete
four level extended page table structure in memory and the abstract
mapping from the guest addresses to the host addresses.
In contrast, for the layer {\code{MATOp}},
which initializes physical memory allocation,
most of the time was spent on verifying
the non-trivial nested loops present in the C code,
while the refinement proofs were derived automatically. 

The proofs were facilitated by automation tools for C
code, layer design patterns, and tactics libraries developed in
recent years \cite{dscal15}. These tools have greatly
reduced the amount of work needed to verify extensions of the kernel.
\ignore{
\jeremie{I do not understand what the following sentence mean
(developing the module vs. ``plugging'' it),
I'm also not sure how it fits with the previous one,
I suggest we just drop it (or move it to Sec.5) and end the paragraph here.}
For example, developing the Intel virtualization module as a certified
kernel plug-in cost over 2 pm. However, plugging this module into
\mCTOSbase{} was done within a person week. \ignore{It took another 2 pm to
link all the proofs together and extract a runnable \mCTOShyper{}
assembly code using the Coq's extraction mechanism.} Modifying and
removing the existing modules does not take much effort either, as
demonstrated by the realization of \mCTOSringz{} and \mCTOSembed{},
which cost 0.5 pm each.
}



\paragraph*{Deployment}
An extended version of \mCTOShyper{} was deployed in context of a large
DARPA-funded research project. It runs on a military land vehicle
using the same hardware configuration we used in the experiments. On
top of the extended version run 6 Ubuntu Linux systems as guests. Each virtual
machine runs several RADL (The Robot Architecture Definition Language)
nodes that have fixed hardware capabilities such as access to GPS,
radar, \etc\\

\ignore{
This section describes our Coq implementation and provides some
actual evaluation of our various efforts. The main point of this
section to show that everything we have talked about so far are
actually real.

List of potential topics/discussions.
\begin{itemize}
\item Challenges met in the Coq implementation.
\item Particular interesting issues or challenges we met during the proof.
\item Any interesting topics we want to talk about in the proof.
\item How the new language constructs eased the task of verification/automation.
\item How we handle invariants. And how separating the invariants from the data helped the automation.
\item Bugs found?
\item Any implementation specific topics?
\item We we designed the layers.
\item Kernel specific challenges and/or interesting topics.
\item Modularity and scalability of our layered approach. How easy it was to extend the kernel with various new constructs?
\item Decide what to submit and acknowledge the work in progress and possible improvements.
\item \emph{anybody want to add more potential items here?}
\end{itemize}
}

\ignore{
\paragraph{Limitations and perspective}
We also try to enumerate all the important limitations of our current
effort. We want to address all possible questions typical readers of
our paper might have and explain why these issues can and will be
addressed in the future. 
}


\ignore{
\begin{figure}\small
\begin{center}
\begin{tabular}{|c|c|}
%\hline
%\multicolumn{2}{|l|}{Development of ClightX and CompCertX} & 10 pm \\
\hline
Physical memory module (3 layers) &  2 pm \\
\hline
Virtual memory module (7 layers) & 2.5 pm \\
\hline
Thread management (10 layers) & 3.5 pm \\
\hline
Process management (4 layers) & 1 pm \\
\hline
Trap handler module (3 layers) & 0.5 pm \\
\hline
\hline
Virtualization (9 layers) for \mCTOShyper{} & 1.5 pm \\
\hline
Changes for \mCTOSringz{}  & 0.5 pm \\
\hline
Changes for \mCTOSembed{}  & 0.5 pm\\
\hline
Linking and code extraction & 2 pm \\
\hline
\end{tabular}
\end{center}
\caption{Effort on verification}
\label{fig:effort}
\end{figure}
}

\ignore{
As shown in Fig.~\ref{fig:effort}, we completed the entire
verification effort of \mCTOS{} in less than 12 person months (pm).  At the
beginning, it took more than 2pm to design and verify the three layers
of physical memory management.  After the proof libraries (e.g. VCGen,
layer design pattern, tactics libraries \textit{etc}.) have been
developed, the average time of designing and verifying one layer was
dramatically reduced. On the verification side, one line of C code can
be proved within 30 lines of Coq code, while one line of assembly
requires only 20 lines of proof.
}

