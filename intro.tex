% Introduction section

\chapter{Introduction}
\label{chap-intro}

\epigraph{{\em We should appreciate
abstraction as our main mental technique to reduce the demands made upon
enumerative reasoning.}{\\ \hfill --- Edsger W. Dijkstra}}


Operating System (OS) kernels and hypervisors form the backbone of
every safety-critical software system in the world.  Hence it is highly
desirable to formally verify the correctness of these
programs~\cite{shao10}.  
Recent efforts
~\cite{klein2009sel4,hawblitzel10,klein14,ironclad14,fscq15,cogent16}
have shown that it is feasible to formally prove the functional
correctness property of simple general-purpose kernels, and file systems, but the cost of such verification is
still quite prohibitive. For example,
it took the seL4 team more than 11 person
years (effort for tool development excluded) to verify 7500 lines of
sequential C code, yet the resulting kernel still contains 1200 lines
of additional C code and 600 lines of assembly code that are not
verified. Worse still, even after all these efforts, all of these systems have ignored the
important issues of concurrency~\cite{kaashoek15,ospp11}, which
include not just user- and I/O concurrency on a single CPU, but also
multicore parallelism with fine-grained locking. This severely limits
the applicability and power of today's formally verified system
software.

\section{Challenges for Building Certified OS Kernels}
\label{sec:intro:challenge}
What makes the verification of OS kernels so challenging?
{\em First, OS kernels are complex artifacts; they contain many
  interdependent components that are difficult to untangle.} Their
invariants can involve machine level details (\eg, how the virtual
memory hardware works) but can also cut across multiple
abstraction boundaries (\eg, different views of an address space
under kernel/user or host/guest modes).  Several
researchers~\cite{baumann12,vaynberg12} observed that even writing
down a good and easy-to-maintain formal specification alone is already
a major roadblock for any such verification effort.


{\em Second, concurrency introduces more complexities.}
Several
researchers~\cite{vontessin13,peters15} believe that the combination
of concurrency and the kernels' functional complexity makes formal
verification of functional correctness intractable, and even if it is
possible, its cost would far exceed that of verifying a single-core
sequential kernel.
First of all, concurrent kernels need to support all three types of
concurrency (user, I/O, or multicore) and make them work coherently
with each other. User and I/O concurrency rely on thread
yield/sleep/wait primitives or interrupts to switch controls and
support synchronization; these constructs are difficult to reason
about since they transfer controls from one thread to another.
Multicore concurrency with fine-grained locking requires sophisticated
spinlock implementations such as MCS locks~\cite{mcs91}, which
 are also
hard to verify.
Furthermore, concurrent kernels should also guarantee that each of their
system calls eventually returns, but this depends on the progress of
the concurrent primitives used in the kernels. Proving
starvation-freedom~\cite{Herlihy08book} for concurrent objects only
became possible recently~\cite{lili16}.  Standard Mesa-style condition
variables~\cite{lampson80} do not guarantee starvation-freedom; this
can be fixed by using a FIFO queue of condition variables, but the
solution is not trivial and even the popular, most up-to-date OS
textbook~\cite[Fig.~5.14]{ospp11} has gotten it
wrong~\cite{anderson16}.

{\em Third, OS kernel verification would not scale if it does not 
support extensibility.} Given the high cost of building concurrent kernels, it is
important that they can be quickly adapted to support new applications
and hardware platforms~\cite{bershad95,engler95,hunt07,unikernel13}. One advantage of a verified
kernel is the existence of formal specifications for all of its
components. In theory, this would allow us to add certified
kernel plug-ins
~\cite{shao10:ctos} 
as long as they do not violate any existing kernel invariants. In
practice, however, if we are unable to decompose kernel invariants
into small independent pieces, even modifying an existing (or adding a
new) verified component may force us to rewrite the proofs for the
entire kernel.


{\em Finally, OS kernels are often written in C, which only supports
  limited forms of abstraction,
  but still lacks the ability to describe hardware details.}
On one hand, the C language (especially ANSI C) is
  too low level to abstract the data representations.
Verifying C programs is
especially hard if they manipulate low-level data structures (\eg,
thread queues, allocation tables). The seL4 effort used an
intermediate executable specification (derived from a Haskell
prototype) to hide some messy C specifics, but this alone is not
enough for enforcing abstraction among different kernel components;
seL4 had to introduce capabilities which add significant
implementation complexities to the kernel.
On the other hand, the C language is
too high level to describe the hardware details
managed and multiplexed by OS kernels.
For example, while most kernel code
can be written in C, many key kernel concepts (\eg, context switches,
address translation, page fault handling) can only be given accurate
semantics at the assembly level. Consequently, we need a formal
assembly model to define many kernel behaviors, but we also want to
verify most kernel code at a much higher abstraction level.



This thesis proposes a new compositional approach that
successfully tackles all of the above challenges in building certified
OS kernels. We believe that, to make verification scale and to provide
strong support to extensibility, we must first have a {\em
  compositional} specification that can untangle {\em all} the kernel
interdependencies. Because the very purpose of an OS kernel is to
build layers of abstraction over bare machines, we insist on
meticulously uncovering and specifying these layers (done in the Coq
proof assistant~\cite{coq}), and then verifying each kernel module at
its {\em proper} abstraction level.
These formally specified and verified layers
are named as {\em certified abstraction layers}.

\section{\CTOS{}: A New Layered Approach}
\label{sec:intro:layer}

We define a {\em certified abstraction
  layer} as a triple $\layer{L_1}{M}{L_2}$ plus a mechanized
proof object the predicate $\ltyp{L_1}{R}{M}{L_2}$, \ignore{for the predicate $\ltyp{L_1}{R}{M}{L_2}$,}
showing that the layer
implementation $M$, built on top of the interface $L_1$ (the {\em
  underlay}), indeed faithfully {\em implements} the desirable
interface $L_2$ above (the {\em overlay}).  The {\em implements}
relation $R$ is defined as a {\em simulation}~\cite{Lynch95}.
A certified layer can be
viewed as a ``parameterized module'' (from interfaces $L_1$ to $L_2$),
{\em a~la} an SML functor~\cite{milner97};
 but it enforces a stronger {\em contextual} correctness property: a correct
layer is like a ``certified compiler,'' capable of converting any {\em
  safe} client program $P$ running on top of $L_2$ into one that has the
same behavior but runs on top of $L_1$ (\eg, by ``compiling'' abstract
primitives in $L_2$ into their implementation in $M$); if
$\sem{L}{\cdot}$ denotes the state machine for layer $L$, the
correctness property (over any context $P$) can be written formally as $\sem{L_1}{P\oplus{}M} \leq_R \sem{L_2}{P}$.

The power of certified abstraction layers lies in 
this {\em contextual refinement}
property,
which guarantees that the overlay interface captures
the precise functionality of the underlying implementation as well as
the assumptions which the implementation might have about its client
contexts.
This overlay interface is called as
a {\em deep specification} 
to the underlay implementation,
and client programs can be understood solely based on this interface, independent of implementation details.

\paragraph{Sequential layer interface}
 contains a  collection of abstract 
\emph{sequential objects}, each of which provides a
set of atomic methods.
The internal abstract states of sequential objects
specify the data representations in the concrete states
(\eg, memory),
and the atomic methods
specify the layer implementations
in terms of the abstract states.
In the sequential setting, the context code $P$ can 
 interfere with the 
layer implementation $M$ is when
$M$ fails to encapsulate its private state.
The contextual refinement relation
between $M$ and $L$ guarantees that
any context code $P$ cannot
modify the internal state of $M$ 
without $M$'s permission.

\paragraph{Concurrent layer interface}
contains a collection of
sequential objects that are thread-private,
and abstract {\em atomic} objects that are shared~\cite{Herlihy08book}. Unlike calls to thread-private abstract objects  which are not {\em observable} by other
threads, each method call to an atomic object is recorded as an 
observable event in the concurrent machine semantics
($\sem{L}{\cdot}$), and is appended to the end of a global log $l$---a
single shared abstract state which we maintain for all the atomic
objects in $L$. The semantics $\sem{L}{P}$ is defined based
on the set of shared logs (\ie, {\em{}traces}, possibly of
infinite length) generated from running the concurrent program $P$
over $L$.

We develop a general compositional (operational) model for
$\sem{L}{P}$ based upon ideas from the game semantics
community~\cite{gsinvite}. Each run of $P$ over $L$ can be viewed as
playing a game involving members of $D$ (plus a scheduler). Each
participant $t$ contributes its play by appending an event into the
global log; its {\em strategy} $\strat{t}$ can be defined as a
deterministic partial function from the current log $l$ to its next
move $\strat{t}(l)$ when the control is transferred to $t$
(defined by the last event in $l$). The
eventual log for executing $P$ over $L$ can then be calculated by
combining the strategies of all the participants.

A concurrent layer interface $L[A]$ can be viewed as a concurrent machine
parameterized over its {\em environment context} $\oracle$, which is a
strategy for its environment (\ie, the scheduler plus those
participants not in $A$).  Given an environment context $\oracle$
which also contains a particular scheduler strategy, the execution of
$P$ over $L[A]$ should be deterministic; the concurrent machine will
run $P$ when control is transferred to any of the participants in $A$, but
will instead ask the environment context $\oracle$ for the next move when 
control is transferred to a member of the environment.
\ignore{As a special case,  $L[t]$ behaves like a
thread-local ``sequential'' machine (albeit parameterized over an
environment context).  }

Therefore, the \emph{context} in the concurrent
setting includes not only the client program $P$,
but also the environment context $\oracle$,
which captures the behaviors
of the context threads or context CPUs,
and all potential interferences.

\section{Contributions and Thesis Outline}
\label{sec:intro:contribution}

This thesis presents \CTOS{}, a novel extensible architecture
for building certified sequential and concurrent OS kernels.
\CTOS{} uses {\em contextual
    refinement} as the unifying formalism to build and
    compose certified abstraction layers for OS kernel components
in both sequential and concurrent settings. 

Before getting into the formal details,
Chapter~\ref{chap:overview}
provides a high-level overview of
\CTOS{} framework,
and  shows how 
certified
  abstraction layers  correspond to a {\em rigorous} 
  form of abstraction over deep specifications used widely
  in the system community. A certified layer interface
  describes not only the precise functionality of any underlying
  implementation but also clear assumptions about its client contexts.
  Abstraction over deep specifications leads to the powerful
  {\em implementation independence} property: 
  any two implementations
  of the same layer interface have contextually equivalent behaviors.
  
Chapter~\ref{chap:seq} proposes 
the \CTOS{} framework in the sequential setting,
and shows how to formally specify,
program, verify, and compose sequential certified abstraction layers. 
We have instantiated the framework on top of two core
  languages: {\bf
    ClightX}, a variant of the CompCert Clight
  language~\cite{blazy-leroy-clight}; and {\bf LAsm}, an x86 assembly
  language.  Both ClightX and LAsm can be used to program certified
  abstraction layers,
  and ClightX abstraction layers are compiled into 
  LAsm layers by a modified CompCert,
  {\bf CompCertX}, a new verified compiler.
    CompCertX is novel because it can prove a stronger
  correctness theorem for compiling individual functions in each
  layer---such a theorem requires reasoning about {\em memory
    injection}~\cite{leroy08} between the memory states of the source
  and target languages.  To support linking between ClightX and LAsm
  layers, we show how to design the {\em implements} relation so that it
  is stable over memory injection.
    As far as we
  know, \CTOS\ is the first architecture that can truly transfer
  global properties proved for user-level programs (at the kernel
  specification level) down to the concrete assembly machine level.
  
\ignore{  Each ClightX or LAsm layer is parameterized
  over its underlay interface, implemented using CompCert's external
  call mechanisms.  We developed new tools and tactic libraries to
  help automate the verification of the {\em implements} relation.}

Using the sequential \CTOS{} framework, we have successfully
  constructed several feature-rich certified sequential OS kernels in Coq.
In   Chapter~\ref{chap:seqkernel},
we show how to decompose the specification of 
a practical general-purpose kernel,
named as \textbf{\mCTOS{}},
into 33 certified abstraction layers, and turn an otherwise 
  prohibitive verification task into many simple and easily automatable 
  sub-tasks.  The resulting kernel is a certified assembly implementation 
  that still enjoys a high degree of compositionality.
  Our layered specification shows that
  {\em interdependent} low-level kernel modules can indeed be
  untangled and given clear formal semantics.
 Using \mCTOS\ as the base, we have also built three additional
  certified kernels: {\bf{}\mCTOShyper} extends \mCTOS\ with virtualization
  support to form a hypervisor kernel ;
  {\bf{}\mCTOSringz} extends \mCTOShyper\ with ``ring 0'' processes
  (they are ``certifiably safe'' application programs that can run safely 
  inside the kernel address space, similar to SIPs in 
  Singularity~\cite{hunt07}); {\bf{}\mCTOSembed} removes virtual memory
  and virtualization support from \mCTOSringz\ so that it only supports 
  ``ring 0'' processes.
  Among these certified kernels,
  the most realistic one is \mCTOShyper{},
  which is written in 5,500 lines of C and x86
assembly, and can boot a version of Linux as a guest.   
  
 Chapter~\ref{chap:con} proposes 
the \CTOS{} framework in the concurrent setting,
 which uses
  contextual refinement over the ``concurrent'' {\em environment contexts}
  ($\oracle$) as the {\em unifying} formalism for composing 
  different concurrent kernel/user objects at different
  abstraction levels.  Each $\oracle$ defines a specific instance on how
  other threads/cores/devices respond toward the events generated by
  the current running threads.  
We show how the use of an environment context at each
  concurrent layer allows us to apply standard techniques for
  verifying sequential programs to verify concurrent programs.
   Indeed, most of our kernel programs are still written 
   in ClightX, and are verified by building
   thread/core-modular ClightX layers.
 These ClightX layers are compiled
 into LAsm layers
   with a {\em thread-safe} version of the CompCertX,
   and are composed at the assembly-level to form
   a complete verified concurrent system.
 To support certified parallel composition of
  thread-modular layers (i.e., $L[t]$ for all $t$), we have developed
  a new extended algebraic memory model (for CompCertX) whereby stack
  frames allocated for each thread can be combined to form a single
  coherent CompCert-style memory.

 Using the concurrent \CTOS framework, we have successfully developed a fully certified
  concurrent OS kernel (called {\bf \cCTOS}),
which  supports both fine-grained locking and sleep-wakeup primitives and
  can run on stock x86 multicore hardware.
  As far as we 
  know, this is the first proof of functional correctness of a complete,
  general-purpose concurrent OS kernel with fine-grained locking.
  Chapter~\ref{chap:conkernel} uses \cCTOS{}
  as a case study to show to apply our framework
  to specify and verify the behaviors of various concurrency
  constructs at different levels of abstraction, such as a multicore
  machine with hardware scheduler, implementation of fine-grained
  synchronization primitives (\eg, spinlocks, queuing locks,
  condition variables), low-level thread primitives (\eg, $\yield$,
  $\sleep$, $\wakeup$), and multi-threading with software scheduler and I/O
  interrupts.
  We prove both the contextual
  correctness of all system calls, as well as a liveness property 
  (\ie,  all system calls will eventually return)
  in a unified setting.
  Following RGSim~\cite{RGSim}, we can impose
  {\em invariants} both over the environment contexts (\ie, the ``rely'')
  and also over the active threads themselves (\ie, the ``guarantee'').
  However, unlike RGSim,
  because each environment context (\ie, the opponent's strategy)
  specifies not just the environment's past behaviors
  but also {\em future behaviors}, we can readily impose temporal
  invariants such as fairness requirements (for schedulers) or
  {\em definite actions}~\cite{lili16} (for releasing locks). This allows
  us to give full specifications for lock primitives and support vertical
  composition of starvation-free atomic objects, none of which have ever
  been done before~\cite{lili16}.
    
    
In Chapter~\ref{chap-eval},   we present a detailed evaluation of our certified development
  effort, including kernel performance, the cost of
  layer design and proof development,
%  the cost of making changes (to certified kernels),
  and the cost of building new extended (or adapted)
  kernels. All of our certified kernels are practical and can run on stock
  x86 hardware. 
    
 Finally, Chapter~\ref{chap-limits} discusses
 the limitations and future work of \CTOS{},
 and Chapter~\ref{chap-rel}
 studies related work and then concludes.
% The full artifact for our entire effort can be accessed at
%   {~\small\url{http://sites.google.com/site/14ctos}}.




\ignore{
\paragraph{POPL15}
Modern hardware and software systems are constructed using a series of
abstraction layers (e.g., circuits, microarchitecture, ISA
architecture, device drivers, OS kernels, hypervisors, network
protocols, web servers, and application APIs), each defining
an interface that hides the implementation details of a particular set
of functionality.  Client programs built on top of each layer can be
understood solely based on the interface, independent of the layer
implementation. Two layer implementations of the same interface should
behave in the same way in the context of any client code.

The power of abstraction layers lies in their use of a very rich class
of specifications, which we will call {\em deep specifications} in
this paper. A deep specification, in theory, is supposed to capture
the precise functionality of the underlying implementation as well as
the assumptions which the implementation might have about its client
contexts. In practice, abstraction layers are almost never formally
specified or verified; their interfaces are often only documented in
natural languages, and thus cannot be rigorously checked or
enforced. Nevertheless, even such informal instances of abstraction
over deep specifications have already brought us huge
benefits. Baldwin and Clark~\cite{baldwin00} attributed such use of
abstraction, modularity, and layering as the key factor that drove the computer
industry toward today's explosive levels of innovation and growth
because {\em complex products can be built from smaller subsystems
  that can be designed independently yet function together as a
  whole}.

Abstraction and modularity have also been heavily studied
in the programming language community~\cite{reynolds98,pierce02}.
The focus there is on abstraction over ``shallow''
specifications. A module interface in existing languages cannot
describe the full functionality of its underlying implementation,
instead, it only describes type specifications, augmented sometimes
with simple invariants.  Abstraction over shallow
specifications is highly desirable~\cite{mitchell86}, but
client programs cannot be understood from the interface alone---this 
makes modular verification of correctness properties
impossible: verification of client programs must look beyond the
interface and examine its underlying implementation, thus breaking the
modularity.

Given the obvious importance, formalizing and verifying abstraction 
layers are highly desirable, but they pose many challenges:
\begin{itemize} \itemsep 0pt
\item
{\em Lack of a language-based model.}  It is unclear how to
  model abstraction layers in a language-based setting and how they
  differ from regular software modules or components.  Each layer
  seems to be defining a new ``abstract machine;'' it may take an
  existing set of mechanisms (e.g., states and functions) at the layer
  below and expose a different view of the same mechanisms. For
  example, a virtual memory management layer---built on top of a
  physical memory layer--- would expose to clients a different view of
  the memory, now accessed through virtual addresses.
%%%%%%%%%%%%%
\item {\em Lack of good language support.} Programming an abstraction
  layer formally, by its very nature, would require two languages: one
  for writing the layer implementation (which, given the low-level
  nature of many layers, often means a language like C or assembly);
  another for writing the formal layer specification (which, given the
  need to precisely specify full functionality, often means a rich
  formal logic). It is unclear how to fit these two different
  languages into a single setting. Indeed, many existing formal
  specification languages~\cite{znot92,lamport94,jackson12} are
  capable of building accurate {\em models} with rich specifications,
  but they are not concerned with connecting to the actual running code.
%%%%%%%%%%%%%
\item {\em Lack of compiler and linking support.} Abstraction layers
  are often deployed in binary or assembly. Even if we can verify a
  layer implementation written in C, it is unclear how to compile it
  into assembly and link it with other assembly layers. The CompCert
  verified compiler~\cite{compcert} can only prove the correctness of
  compilation for whole programs, not individual modules or
  layers. Linking C with assembly adds a new challenge since they may
  have different memory layouts and calling conventions.
\end{itemize}

In this paper, we present a formal study of abstraction layers that
tackles all these challenges. We define a {\em certified abstraction
  layer} as a triple $\layer{L_1}{M}{L_2}$ plus a mechanized proof
object showing that the layer implementation $M$, built on top of the
interface $L_1$ (the {\em underlay}), indeed faithfully {\em
  implements} the desirable interface $L_2$ above (the {\em overlay}).
Here, the {\em implements} relation is often defined as some
{\em simulation} relation~\cite{Lynch95}.  A certified layer can be
viewed as a ``parameterized module'' (from interfaces $L_1$ to $L_2$),
{\em a~la} an SML functor~\cite{milner97}; but it enforces a stronger
contextual correctness property: a correct layer is like a
``certified compiler,'' capable of converting any {\em safe} client program
running on top of $L_2$ into one that has the same behavior but runs
on top of $L_1$ (e.g., by ``compiling'' abstract primitives in $L_2$ into
their implementation in $M$). 

% A regular module $M$, which builds on top of $L_1$ and
% implements $L_2$, may not enjoy such a property. A client program $P$
% may invoke functions defined in $M$ and in another module $M'$.  Such
% $M'$ may share some state with $M$ but imposes state invariants that
% are in conflict with those assumed by $L_2$.  An abstraction layer
% does not allow such a client $P$, instead, such $M'$ must be either
% built on top of $L_2$ (thus respecting the invariants in $L_2$), or
% below $L_2$ (in which case, $L_2$ itself must be changed).

A regular software module $M$ (built on top of $L_1$) with interface
$L_2$ may not enjoy such a property because its client may invoke
another module $M'$ which shares some states with $M$ but imposes
different state invariants from those assumed by $L_2$. An abstraction
layer does not allow such a client, instead, such $M'$ must be either built
on top of $L_2$ (thus respecting the invariants in $L_2$), or below
$L_2$ (in which case, $L_2$ itself must be changed).

%
% Each layer interface $L$ contains a {\em deep} specification of a set
% of functionality in that given any client program $P$ (sanctioned by
% $L$), its execution on top of $L$ always yield deterministic behaviors
% (relative to external events, e.g., I/O, scheduling~\cite{leroy06,sevcik13})
%

Our paper makes the following new contributions:
\begin{enumerate}
\item We present the first language-based account of certified
  abstraction layers and show how they correspond to a {\em rigorous} 
  form of abstraction over deep specifications used widely
  in the system community. A certified layer interface
  describes not only the precise functionality of any underlying
  implementation but also clear assumptions about its client contexts.
  Abstraction over deep specifications leads to the powerful
  {\em implementation independence} property
  (see Sec.~\ref{sec:overview}): 
  any two implementations
  of the same layer interface have contextually equivalent behaviors.
%%%%%%%%%%%%%
\item We present a new layer calculus showing how to formally specify,
  program, verify, and compose certified abstraction layers 
  (see Sec.~\ref{sec:layer}). Such a
  layer language plays a similar role as the module language in
  SML~\cite{milner97}, but its interface checking is not just
  typechecking or signature matching; instead, it requires formal
  verification of the {\em implements} relation in a proof assistant.
%%%%%%%%%%%%%
\item We have instantiated the layer calculus on top of two core
  languages (see Sec.~\ref{sec:prog} and ~\ref{sec:lasm}): {\bf
    ClightX}, a variant of the CompCert Clight
  language~\cite{blazy-leroy-clight}; and {\bf LAsm}, an x86 assembly
  language.  Both ClightX and LAsm can be used to program certified
  abstraction layers.  We use the Coq logic~\cite{coq} to develop all
  the layer interfaces.  Each ClightX or LAsm layer is parameterized
  over its underlay interface, implemented using CompCert's external
  call mechanisms.  We developed new tools and tactic libraries to
  help automate the verification of the {\em implements} relation.
%%%%%%%%%%%%%
\item We have also modified CompCert to build a new verified compiler,
  {\bf CompCertX}, that can compile ClightX abstraction layers into
  LAsm layers (see Sec.~\ref{sec:comp}). 
  CompCertX is novel because it can prove a stronger
  correctness theorem for compiling individual functions in each
  layer---such a theorem requires reasoning about {\em memory
    injection}~\cite{leroy08} between the memory states of the source
  and target languages.  To support linking between ClightX and LAsm
  layers, we show how to design the {\em implements} relation so that it
  is stable over memory injection.
%%%%%%%%%%%%%
\item Using these new languages and tools, we have successfully
  constructed several feature-rich certified OS kernels in Coq (see
  Sec.~\ref{sec:kernel}).  A certified kernel
  $\layer{L_{\raw}}{K}{L_{\sys}}$ is a verified LAsm implementation
  $K$, built on top of $L_{\raw}$, and it {\em implements} the set of
  system calls as specified in $L_{\sys}$.  The correctness of the
  kernel guarantees that if a user program $P$ runs {\em safely} on
  top of $L_{\sys}$, running the version of $P$ linked with the kernel
  $K$ on $L_{\raw}$ will produce the same behavior.  All our certified
  kernels are built by composing a collection of smaller layers.
  The most realistic kernel consists of 37 layers, took less than one
  person year to develop, and can boot a version of Linux as a guest.
\end{enumerate}

\noindent{}The {\em POPL Artifact Evaluation Committee} reviewed the
full artifact of our entire effort, including ClightX and LAsm,
the CompCertX compiler, and the implementation of all
certified kernels with Coq proofs. 
The reviewers unanimously stated
that our implementation {\em exceeded their expectations}, with one
reviewer rating the paper as one of the most solid papers he/she has
ever seen. Additional details about our work can be found in
the companion technical report~\cite{dscal14tr}.
%
%\begin{verbatim}
%   flint.cs.yale.edu/publications/aec14.html
%\end{verbatim}
%

\paragraph{Roadmap.}
This thesis is organized as follows.
$\S$\ref{sec:overview} explains why layers support 
abstraction over deep specifications better than regular modules do.
$\S$\ref{sec:layer} presents the formal layer calculus.
$\S$\ref{sec:prog} and $\S$\ref{sec:lasm} describe the new ClightX and
LAsm languages and show how to use them to build certified layers.
$\S$~\ref{sec:comp} presents the new CompCertX compiler and shows how
to link ClightX layers with LAsm layers.  $\S$\ref{sec:kernel} gives
an overview of the certified OS kernels we have constructed.
$\S$\ref{sec:related} and $\S$\ref{sec:concl} discuss related work and
then conclude.


\paragraph{POPL17}
Abstraction layers (e.g., circuits, microarchitecture, ISA, device
drivers, OS kernels, hypervisors, network protocols, and application
APIs)~\cite{salzer09,baldwin00} are widely used in modern computer
systems to help reduce the complex interdependencies among components
at different levels of abstraction.  An abstraction layer defines an
interface that hides the implementation details of its underlying
software or hardware components. Client programs built on top of each
layer can be understood solely based on the interface, independent of
the layer implementation.

As multicore hardware and multithreaded programming become more
pervasive, many of these abstraction layers also become {\em
  concurrent} in nature.  Their interfaces not only hide the concrete
data representations and algorithmic details, but also create an
illusion of {\em atomicity} for all of their methods: each method call
can be viewed as if it completes in a single step, even though its
implementation contains complex interleavings with operations done by
other threads.  Herlihy~{\em{}et~al.}~\cite{herlihy90,Herlihy08book}
advocated using these concurrent atomic objects as the key building
blocks for constructing large-scale shared-memory concurrent software
systems.

\citet{dscal15} showed that specifying and verifying large-scale
complex system software (e.g., OS kernels and hypervisors) can also
benefit greatly from aggressive layer decomposition. They developed a
formal theory of certified (sequential) abstraction layers, as well as a
set of new certified programming tools.  A {\em certified abstraction
  layer} is defined as a triple $\layer{L'}{M}{L}$ plus a mechanized
proof object for the predicate $\ltyp{L'}{R}{M}{L}$, showing that the layer
implementation $M$, built on top of the interface $L'$ (the {\em
  underlay}), indeed faithfully {\em implements} the desirable
interface $L$ above (the {\em overlay}).  The {\em implements}
relation $R$ is defined as a {\em simulation}~\cite{Lynch95} but it
enforces a stronger {\em contextual} correctness property: a correct
layer is like a ``certified compiler,'' capable of converting any {\em
  safe} client program $P$ running on top of $L$ into one that has the
same behavior but runs on top of $L'$ (e.g., by ``compiling'' abstract
primitives in $L$ into their implementation in $M$); if
$\sem{L}{\cdot}$ denotes the state machine for layer $L$, the
correctness property (over context $P$) can be written formally as
$\sem{L'}{P\oplus{}M} \leq_R \sem{L}{P}$.

Unfortunately, the theory developed by \citet{dscal15} does not easily
carry over to the concurrent setting. Concurrent abstraction layers
pose many new technical challenges:
\begin{itemize} \itemsep 0pt
\item 
  {\em Lack of a general compositional model.} It is unclear how to
  define a general thread-modular semantic framework so that the
  behavior of each concurrent abstraction machine (e.g.,
  $\sem{L}{\cdot}$ for a layer interface $L$) can be constructed from the
  behaviors of each of its threads or CPU cores. More specifically, if
  $D$ denotes the set of all possible threads and CPU cores, $A$ is a
  subset of $D$, and $L[A]$ denotes the layer $L$ with members of $A$
  being {\em active} (i.e., members outside $A$ are considered as the
  {\em environment}), can we construct the semantics of the abstract
  machine $\sem{L[A]}{\cdot}$ from those of $\sem{L[t]}{\cdot}$
  for all $t\in{}A$? Note for readability, we have abbreviated
  $\{t\}$ as $t$, so $L[t]$ really denotes $L[\{t\}]$.
%%%%%%%%%%%%%
\item {\em Lack of a general parallel layer composition rule.}
  \citet{dscal15} supports both horizontal and vertical layer
  composition, but even with a compositional concurrency model, and
  supposing we can perform thread-modular reasoning to prove the
  ``contextual'' simulation property $\ltyp{L'[t]}{R}{M}{L[t]}$ for
  each $t\in{}D$, we still need a general ``parallel layer composition''
  rule to show that the contextual simulation holds for the whole
  concurrent machine $\ltyp{L'[D]}{R}{M}{L[D]}$.
  Liang~{\em{}et~al.}\cite{RGSim,Liang14lics,lili16} developed a
  Rely-Guarantee-based Simulation (RGSim) that is compositional over
  simple parallel composition constructs (e.g., $C_1 \| C_2$), but
  it is unclear how to extend it to support richer language constructs
  and vertical composition of multiple concurrent layers.
%%%%%%%%%%%%%
\item {\em Lack of compiler and linking support.} \citet{dscal15}
  developed a new CompCertX compiler that can compile certified
  ClightX layers into certified assembly layers. However, neither
  CompCertX nor the original CompCert compiler~\cite{leroy08} supports
  concurrent programs. It is unclear how to turn CompCertX into a
  thread-safe verified compiler, and how to use it to compile a
  certified concurrent C program into assembly and then link it with
  other concurrent assembly layers.
\end{itemize}

In this paper, we present a new formal framework that tackles all of
the above challenges for specifying, programming, compiling, and
composing certified concurrent abstraction layers. We extend each
layer interface $L$ in \citet{dscal15} with a collection of abstract
{\em atomic} objects~\cite{Herlihy08book}, each of which provides a
set of atomic methods. Unlike calls to thread-private abstract objects
(as in \cite{dscal15}) which are not {\em observable} by other
threads, each method call to an atomic object is recorded as an 
observable event in the concurrent machine semantics
($\sem{L}{\cdot}$), and is appended to the end of a global log $l$---a
single shared abstract state which we maintain for all the atomic
objects in $L$. The semantics $\sem{L}{P}$ can then be defined based
on the set of shared logs (i.e., {\em{}traces}, possibly of
infinite length) generated from running the concurrent program $P$
over $L$.

We develop a general compositional (operational) model for
$\sem{L}{P}$ based upon ideas from the game semantics
community~\cite{gsinvite}. Each run of $P$ over $L$ can be viewed as
playing a game involving members of $D$ (plus a scheduler). Each
participant $t$ contributes its play by appending an event into the
global log; its {\em strategy} $\strat{t}$ can be defined as a
deterministic partial function from the current log $l$ to its next
move $\strat{t}(l)$ when the control is transferred to $t$
(defined by the last event in $l$). The
eventual log for executing $P$ over $L$ can then be calculated by
combining the strategies of all the participants.

A layer interface $L[A]$ can be viewed as a concurrent machine
parameterized over its {\em environment context} $\oracle$, which is a
strategy for its environment (i.e., the scheduler plus those
participants not in $A$).  Given an environment context $\oracle$
which also contains a particular scheduler strategy, the execution of
$P$ over $L[A]$ should be deterministic; the concurrent machine will
run $P$ when control is transferred to any of the participants in $A$, but
will instead ask the environment context $\oracle$ for the next move when 
control is transferred to a member of the environment.

The new compositional model allows us to prove a general parallel
layer composition rule. Furthermore, $L[t]$ behaves like a
thread-local ``sequential'' machine (albeit parameterized over an
environment context).  This makes it possible to adapt the CompCertX
compiler so that it can be used to compile a certified ClightX layer
$(L'[t],M,L[t])$ into a certified assembly layer. We can then apply
both the horizontal and vertical layer composition rules (as developed
by \citet{dscal15}) along with the new parallel composition rule to 
construct fully certified concurrent software.
 
Our paper makes the following new contributions:
\begin{itemize} \itemsep 0pt
%%%%%%%%%%%%%
\item We present the first language-based account of certified
  concurrent abstraction layers and show that complex concurrent
  software can indeed be decomposed into layers of simple concurrent
  atomic objects while still supporting thread-modular reasoning.
  Following \citet{dscal15}, for each certified layer, we prove a {\em
    termination-sensitive} contextual correctness property. In the
  concurrent setting, this means that every certified concurrent
  object satisfies not only a safety property (e.g., {\em
    linearizability})~\cite{herlihy90,filipovic10} but also a
  progress property (e.g., {\em
    starvation-freedom})~\cite{liang13,lili16}.
%%%%%%%%%%%%%
\item We present a new compositional semantic model for shared-memory
  concurrent abstract machines and prove a general parallel layer
  composition rule. Our new framework is general in that it can be
  used to specify and verify the behaviors of various concurrency
  constructs at different levels of abstraction, such as a multicore
  machine with hardware scheduler, implementation of fine-grained
  synchronization primitives (e.g., spinlocks, queuing locks,
  condition variables), low-level thread primitives (e.g., $\yield$,
  $\sleep$, $\wakeup$), and multi-threading with software scheduler and I/O
  interrupts.
%%%%%%%%%%%%%
\item We show how to apply standard {\em simulation} techniques
  (as in \cite{compcert,dscal15}) to verify
  both the contextual correctness and liveness properties in a unified setting.
  Following RGSim~\cite{RGSim}, we can impose
  {\em invariants} both over the environment contexts (i.e., the ``rely'')
  and also over the active threads themselves (i.e., the ``guarantee'').
  However, unlike RGSim,
  because each environment context (i.e., the opponent's strategy)
  specifies not just the environment's past behaviors
  but also {\em future behaviors}, we can readily impose temporal
  invariants such as fairness requirements (for schedulers) or
  {\em definite actions}~\cite{lili16} (for releasing locks). This allows
  us to give full specifications for lock primitives and support vertical
  composition of starvation-free atomic objects, none of which have ever
  been done before~\cite{lili16}.
%%%%%%%%%%%%%
\item We have successfully extended the layered programming languages
  ClightX (a C variant) and LAsm (an x86 assembly language) by
  \citet{dscal15} with support for concurrent layered programming.  We
  have also developed a new {\em thread-safe} version of the CompCertX
  compiler that can compile certified concurrent ClightX layers into
  LAsm layers.  To support certified parallel composition of
  thread-modular layers (i.e., $L[t]$ for all $t$), we have developed
  a new extended algebraic memory model (for CompCertX) whereby stack
  frames allocated for each thread can be combined to form a single
  coherent CompCert-style memory.
%%%%%%%%%%%%%
\item Using these new languages and tools, we have successfully
  constructed a certified concurrent OS kernel in the Coq proof
  assistant~\cite{coq}. Our certified kernel supports not just user-
  and I/O concurrency on a single CPU, but also multicore parallelism
  with fine-grained locking. We prove both the contextual
  correctness of all system calls, as well as a liveness property 
  saying that all system calls will eventually return.  As far as we 
  know, this is the first proof of functional correctness of a complete,
  general-purpose concurrent OS kernel with fine-grained locking.
\end{itemize}

The full artifact for our entire effort, including the new ClightX and
LAsm languages for concurrent layered programming, the thread-safe
CompCertX compiler, and the implementation of our certified concurrent
OS kernel have been uploaded as supplementary materials on the POPL
2017 submission site.

The rest of this paper is organized as follows.
Sec.~\ref{sec:informal} gives an overview of a few key high-level
ideas for building certified concurrent layers.  Sec.~\ref{sec:layer}
presents the formal framework for specifying, verifying, and composing
concurrent layers.  Sec.~\ref{sec:mach}-\ref{sec:prog}
describe our layered concurrent machine models and  
show how to use them to build certified
concurrent layers.  Sec.~\ref{sec:comp} presents the new thread-safe
CompCertX compiler and shows how to link ClightX layers
with concurrent LAsm layers.  Sec.~\ref{sec:kernel} gives an overview
of the certified concurrent OS kernel that we have constructed.
Sec.~\ref{sec:related} discusses related work and then concludes.

Finally, note that throughout this paper, all of our concurrent 
abstract machines assume strong sequential consistency for atomic 
primitives. Supporting relaxed memory models is left as future work. 


\paragraph{SOSP15}

Operating System (OS) kernels and hypervisors form the backbone of
every safety-critical software system in the world.  Hence it is highly
desirable to formally verify the correctness of these
programs~\cite{shao10}.  
Recent work on seL4~\cite{klein2009sel4,klein14} has shown that it is
feasible to formally prove the functional correctness property of a
general-purpose microkernel, but the cost of such verification is
still quite prohibitive. It took the seL4 team more than 11 person
years (effort for tool development excluded) to verify 7500 lines of
sequential C code, yet the resulting kernel still contains 1200 lines
of additional C code and 600 lines of assembly code that are not
verified. Worse still, even after all these efforts, the current
verified seL4 kernel cannot be used to reason about user-level
programs as it does not verify important features such as
virtual-memory page faults and address translation.

What makes the verification of OS kernels so challenging?
{\em First, OS kernels are complex artifacts; they contain many
  interdependent components that are difficult to untangle.} Their
invariants can involve machine level details (e.g., how the virtual
memory hardware works) but can also cut across multiple
abstraction boundaries (e.g., different views of an address space
under kernel/user or host/guest modes).  Several
researchers~\cite{baumann12,vaynberg12} observed that even writing
down a good and easy-to-maintain formal specification alone is already
a major roadblock for any such verification effort.

{\em Second, OS kernels are often written in C, which only supports
  limited forms of abstraction.}  Verification of C programs is
especially hard if they manipulate low-level data structures (e.g.,
thread queues, allocation tables).  The seL4 effort used an
intermediate executable specification (derived from a Haskell
prototype) to hide some messy C specifics, but this alone is not
enough for enforcing abstraction among different kernel components;
seL4 had to introduce capabilities which add significant
implementation complexities to the kernel.

{\em Third, OS kernels are developed for managing and multiplexing
  hardware, so it is important to have a machine model that can
  describe hardware details.} The C language (especially ANSI C) is
too high level for this purpose. For example, while most kernel code
can be written in C, many key kernel concepts (e.g., context switches,
address translation, page fault handling) can only be given accurate
semantics at the assembly level. Consequently, we need a formal
assembly model to define many kernel behaviors, but we also want to
verify most kernel code at a much higher abstraction level.

{\em Fourth, OS kernel verification would not scale if it does not 
support extensibility.} One advantage of a verified
kernel is the existence of formal specifications for all of its
components. In theory, this would allow us to add certified
kernel plug-ins
~\cite{shao10:ctos} 
as long as they do not violate any existing kernel invariants. In
practice, however, if we are unable to decompose kernel invariants
into small independent pieces, even modifying an existing (or adding a
new) verified component may force us to rewrite the proofs for the
entire kernel.

In this paper, we present a novel compositional approach that
successfully tackles all of the above challenges in building certified
OS kernels. We believe that, to make verification scale and to provide
strong support to extensibility, we must first have a {\em
  compositional} specification that can untangle {\em all} the kernel
interdependencies. Because the very purpose of an OS kernel is to
build layers of abstraction over bare machines, we insist on
meticulously uncovering and specifying these layers (done in the Coq
proof assistant~\cite{coq}), and then verifying each kernel module at
its {\em proper} abstraction level.

The functional correctness of an OS kernel (as done in seL4) is
usually stated as a {\em refinement} property. Roughly speaking, if
$\mimp$ stands for the C/assembly implementation of a kernel, $\mabs$
for its abstract functional specification, and $\sem{}{\cdot}$ for
each's corresponding state machine, then $\mimp$ refines $\mabs$ if
there exists a {\em forward simulation}~\cite{Lynch95} from
$\sem{}{\mimp}$ to $\sem{}{\mabs}$ (denoted as $\sem{}{\mimp} \Refrel
\sem{}{\mabs}$).  Through such refinement, Gerwin {\em et
  al}~\cite{klein14,murray13,sewell11,sewell13} claimed that many
properties established for $\mabs$ (e.g.,
confidentiality~\cite{murray13} when $\mabs$ is deterministic) can be
transferred to $\mimp$.

This claim, unfortunately, fails to hold in the context of any
interesting user-level programs. If $P$ stands for a collection of
user-level processes and $\;\join\;$ for a linking operator, then from
$\sem{}{\mimp} \Refrel \sem{}{\mabs}$ alone, we cannot derive
$\sem{}{\mimp\join{}P} \Refrel \sem{}{\mabs\join{}P}$. This is because
the semantics of running $P$ on top of $\mabs$ (where virtual memory
hardware is hidden) is different from that of running $P$ on top of
$\mimp$ (where page faults and address translation do come into play).
Daum~{\em et al}~\cite{daum14} partially closed the gap by extending
the original refinement proof to also track memory permissions, but
they still did not deal with page faults in their model of user
transitions.  In this paper, we instead prove the strong {\em
  contextual refinement} property for all kernel modules {\em
  directly}: we show that for any kernel/user or host/guest context
code $P$, $\sem{}{\mimp\join{}P} \Refrel \sem{}{\mabs\join{}P}$ always
holds. This guarantees that we cannot overlook any subtle difference
between machines at different abstraction levels.

Our paper makes the following new contributions:
\begin{itemize} \itemsep 0pt
\item We present {\bf{}\CTOS}---a new extensible architecture for
  building certified OS kernels. \CTOS\ uses {\em contextual
    refinement} as the unifying formalism for composing kernel and
  user components at different abstraction levels.  Each abstraction
  layer is defined as an assembly-level machine extended with a
  particular set of abstract states and primitives.  However, most of
  our kernel programs are written in a variant of C (called
  ClightX)~\cite{dscal15}, verified at the source level, and compiled
  and linked together using a modified version~\cite{dscal15} of the
  CompCert verified compiler~\cite{compcert,leroy09}.  As far as we
  know, \CTOS\ is the first architecture that can truly transfer
  global properties proved for user-level programs (at the kernel
  specification level) down to the concrete assembly machine level.
%%%%%%%
\item Using \CTOS, we have developed a fully certified
  {\bf \mCTOS} kernel in Coq. Unlike seL4, 
  we decompose the specification of \mCTOS\ 
  into 33 {\em logical} abstraction layers, and turn an otherwise 
  prohibitive verification task into many simple and easily automatable 
  sub-tasks. The resulting kernel is a certified assembly implementation 
  that still enjoys a high degree of compositionality.
  Our layered specification shows that
  {\em interdependent} low-level kernel modules can indeed be
  untangled and given clear formal semantics.
%%%%%%%
\item Using \mCTOS\ as the base, we have also built three additional
  certified kernels: {\bf{}\mCTOShyper} extends \mCTOS\ with virtualization
  support to form a hypervisor kernel;
  {\bf{}\mCTOSringz} extends \mCTOShyper\ with ``ring 0'' processes
  (they are ``certifiably safe'' application programs that can run safely 
  inside the kernel address space, similar to SIPs in 
  Singularity~\cite{hunt07}); {\bf{}\mCTOSembed} removes virtual memory
  and virtualization support from \mCTOSringz\ so that it only supports 
  ``ring 0'' processes.
%%%%%%%
\item We present a detailed evaluation of our certified development
  effort, including kernel performance, the cost of
  layer design and proof development,
%  the cost of making changes (to certified kernels),
  and the cost of building new extended (or adapted)
  kernels. All of our certified kernels are practical and can run on stock
  x86 hardware. Our certified hypervisor kernel (\mCTOShyper) consists
  of 5500 lines of C and x86 assembly, and can successfully boot 
  a version of Linux as a guest. The entire specification and proof effort 
  took less than 1.5 person years. 
\end{itemize}

The rest of this paper is organized as follows.
Sec.~\ref{sec:overview} gives an overview of our new
\CTOS\ architecture. Sec.~\ref{sec:spec} presents the layer design
process and common principles we have followed. Sec.~\ref{sec:base}
and~\ref{sec:adapt} present the detailed development of the
\mCTOS\ kernel and variants and how we prove certain global properties.
Sec.~\ref{sec:imp} gives a detailed evaluation about our
implementation. Sec.~\ref{sec:related} % and~\ref{sec:concl}
discusses
related work and then concludes.  The full artifact for our entire
effort can be accessed at
{~\small\url{http://sites.google.com/site/14ctos}}.


\paragraph{OSDI16}
Operating System (OS) kernels and hypervisors form the backbone of
every safety-critical software system in the world.  Hence it is
highly desirable to formally verify the correctness of these
programs~\cite{shao10}. 
Recent efforts~\cite{klein2009sel4,hawblitzel10,klein14,ironclad14,dscal15,fscq15,cogent16,chen16}
have shown that it is feasible to formally prove the functional
correctness property of simple general-purpose kernels, file systems,
and device drivers, but all of these systems have ignored the
important issues of concurrency~\cite{kaashoek15,ospp11}, which
include not just user- and I/O concurrency on a single CPU, but also
multicore parallelism with fine-grained locking. This severely limits
the applicability and power of today's formally verified system
software.

What makes the verification of concurrent OS kernels so challenging?
First, concurrent kernels allow interleaved execution of kernel/user
modules across different abstraction layers; they contain many
interdependent components that are difficult to untangle.  Several
researchers~\cite{vontessin13,peters15} believe that the combination
of concurrency and the kernels' functional complexity makes formal
verification of functional correctness intractable, and even if it is
possible, its cost would far exceed that of verifying a single-core
sequential kernel.

Second, concurrent kernels need to support all three types of
concurrency (user, I/O, or multicore) and make them work coherently
with each other. User and I/O concurrency rely on thread
yield/sleep/wait primitives or interrupts to switch controls and
support synchronization; these constructs are difficult to reason
about since they transfer controls from one thread to another.
Multicore concurrency with fine-grained locking requires sophisticated
spinlock implementations such as MCS locks~\cite{mcs91}, which are also
hard to verify.

Third, concurrent kernels should also guarantee that each of their
system calls eventually returns, but this depends on the progress of
the concurrent primitives used in the kernels. Proving
starvation-freedom~\cite{Herlihy08book} for concurrent objects only
became possible recently~\cite{lili16}.  Standard Mesa-style condition
variables~\cite{lampson80} do not guarantee starvation-freedom; this
can be fixed by using a FIFO queue of condition variables, but the
solution is not trivial and even the popular, most up-to-date OS
textbook~\cite[fig~5.14]{ospp11} has gotten it
wrong~\cite{anderson16}.

Fourth, given the high cost of building concurrent kernels, it is
important that they can be quickly adapted to support new applications
and hardware platforms~\cite{bershad95,engler95,hunt07,unikernel13}.
One advantage of a certified kernel is the formal specification for
all of its components. In theory, this allows us to add certified
kernel plug-ins as long as they do not violate any existing
invariants.  In practice, however, if these invariants are complex,
and if we are unable to encapsulate interference, even a small edit
could incur huge verification overhead.

In this paper, we present a novel compositional approach that tackles
all these challenges. We believe that, to control the complexity of
concurrent kernels and to provide strong support for extensibility, we
must first have a {\em compositional} specification that can untangle
{\em all} the kernel interdependencies and encapsulate interference
among different kernel objects. Because the very purpose of an OS
kernel is to build layers of abstraction over bare machines, we insist
on meticulously uncovering and specifying these layers, and then
verifying each kernel module at its {\em proper} abstraction level.

The functional correctness of an OS kernel (as done in
seL4~\cite{klein14}) is usually stated as a {\em refinement}
property. This can be shown by constructing a {\em forward
  simulation}~\cite{Lynch95} from the C/assembly implementation of a
kernel ($K$) to its abstract functional specification ($S$). Of
course, the ultimate goal of having a certified kernel is to reason
about programs running on top of (or along with) the kernel. It is
thus important to ensure that given any kernel extension or user
program $P$, the combined code $K\join{}P$ also refines
$S\join{}P$. If this fails to hold, the kernel is simply still
incorrect since $P$ can observe the difference between $K$
and $S$. \citet{dscal15} advocated proving such a {\em
contextual refinement} property, but they only considered the {\em
sequential} contexts (\ie, $P$ is sequential).

For concurrent kernels, proving the {\em contextual refinement}
property becomes essential. In the sequential setting, the only way
that the context code $P$ can interfere with the kernel $K$ is when
$K$ fails to encapsulate its private state, that is, $P$ can
modify some internal state of $K$ without $K$'s permission.
In the concurrent setting, the {\em environment} context ($\oracle$)
of a running kernel $K$ could be other kernel threads or a copy of $K$
running on another CPU. With shared-memory concurrency, the
interference between $\oracle$ and $K$ are both necessary and often
common; the sequential {\em atomic} specification $S$ is now replaced
by the notion of linearizability~\cite{herlihy90} plus a progress
property such as starvation-freedom.

In fact, linearzability proofs often require event reordering that
preserves the happens-before relation, so $K\,\join{}\,\oracle$ may not
even refine $S\,\join{}\,\oracle$.  Contextual refinement in the
concurrent setting requires that for any $\oracle$, we can find a {\em
  semantically related}\ $\oracle'$ such that $K\,\join{}\,\oracle$ refines
$S\,\join{}\,\oracle'$.  Several
researchers~\cite{filipovic10,liang13,lili16} have shown that
contextual refinement is precisely equivalent to the linearizability
and progress requirements for implementing concurrent
objects~\cite{Herlihy08book,herlihy90}.

Our paper makes the following contributions:
\begin{itemize} \itemsep 0pt
\item We present {\bf{}\CTOS}---a new extensible architecture for
  building certified concurrent OS kernels.  \CTOS\ uses 
  contextual refinement over the ``concurrent'' {\em environment contexts}
  ($\oracle$) as the {\em unifying} formalism for composing 
  different concurrent kernel/user objects at different
  abstraction levels.  Each $\oracle$ defines a specific instance on how
  other threads/cores/devices respond toward the events generated by
  the current running threads.  Each abstraction layer, 
  parameterized over a specific $\oracle$, is an
  assembly-level machine extended with a particular set of
  abstract objects (\ie, abstract states plus atomic primitives).
  \CTOS\ successfully decomposes an
  otherwise prohibitive verification task into many simple and easily
  automatable ones.
%%%%%%%
\item We show how the use of an environment context at each
  layer allows us to apply standard techniques for
  verifying sequential programs to verify concurrent programs.
  Indeed, most of our kernel programs are written in a variant of C
  (called ClightX)~\cite{dscal15}, verified at the source level, and
  compiled and linked together using
  CompCertX~\cite{dscal15}---a {\em thread-safe} version of the CompCert
  compiler~\cite{compcert,leroy09}. As far as we
  know, \CTOS\ is the first architecture that can truly build
  certified concurrent kernels and transfer global properties proved
  for programs (at the kernel specification level) down to the
  concrete assembly machine level.
%%%%%%%
\item We show how to impose temporal invariants over these environment
  contexts so we can verify the progress properties of various
  concurrent primitives. For example, to verify the starvation-freedom
  of ticket locks or MCS locks, we must assume that the multicore
  hardware (or the OS scheduler) always generates a {\em fair}
  interleaving, and those threads/cores which requested locks before
  the current running thread will eventually acquire and then release
  the lock. We show how these assumptions (over the environment contexts)
  can be discharged when we compose different threads/cores to form
  a complete verified system.
%%%%%%%
\item Using \CTOS, we have successfully developed a fully certified
  concurrent OS kernel (called {\bf \mCTOS}) in Coq~\cite{coq}.  Using
  \mCTOS\ as the base, we have also built a few additional certified
  kernels with hypervisor or ring-0 process supports.  Our kernels
  support both fine-grained locking and sleep-wakeup primitives and
  can run on stock x86 multicore hardware. Our certified hypervisor
  kernel consists of 6000 lines of C and x86 assembly, and can boot a
  version of Linux as a guest.
  % The specification and proof effort took less than two person years.
  To our knowledge, this is the
  first proof of functional correctness of a complete, general-purpose
  concurrent OS kernel with fine-grained locking.
\end{itemize}

The rest of this paper is organized as follows.
Sec.~\ref{sec:overview} gives an overview of our new
\CTOS\ architecture. Sec.~\ref{sec:machine} shows how we use
environment contexts to turn concurrent layers into sequential ones. 
Sec.~\ref{sec:base} presents the development of the
\mCTOS\ kernel and how we verify various concurrent kernel
objects. Sec.~\ref{sec:imp} presents an evaluation of \CTOS. 
Sec.~\ref{sec:related} discusses related work and then concludes.
% The full artifact for our entire effort can be accessed at
%   {~\small\url{http://sites.google.com/site/14ctos}}.
}




