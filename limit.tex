\chapter{Limitations and Future Work}
\label{chap-limits}
%\sectskip
%\asectskip

%\zhong{
%Here we address all potential loose-ends.
%\begin{itemize}
%\item any lessons learned?
%\item concurrency and contextual refinement
%\item liveness properties 
%\item compcert memory references vs. capabilities (security properties)
%\item resource usages (stack usages)
%\item interrupts and interrupt handler
%\end{itemize}
%}


\paragraph{Trusted computing base (TCB)}
Currently, there is still some gap between the machine model we rely on and he real x86 hardware.
In the sequential setting,
the bottommost layer of our
verified kernel, {$L_\code{PreInit}$}, does not model
some  hardware features (\eg, TLB) and virtualization
instructions (\eg, \code{vmrun}, \code{vmload}, \code{vmsave}). 
These hardware features can be gradually introduced into our framework in the future. Thanks to the horizontal composition,
these features and newly introduced primitives can be lifted to the related layers with minimal changes to the rest.

In the concurrent settting,
our assembly machine $\mach{x86mc}$ assumes strong sequential consistency for all
atomic instructions. Nevertheless, our proof remains valid for the x86
TSO model. All our concurrent layers guarantee that non-atomic memory
accesses are properly synchronized.  The TSO order guarantees that all
atomic synchronization operations are properly ordered (and there is
no need to insert any explicit fences).  \citet{vontessin13} shows how
to turn proofs over sequential-consistent machines into those over
the TSO machines.

Outside our verified kernels
(\cCTOS{} consists of about 6000 lines of C and assembly), there
are 300 lines of C and 170 lines of x86 assembly code that are not
verified yet: the ELF loader used by user
process creation
and the preinit procedure, which initializes the drivers, \eg,
disk, console, {\etc}
Although these primitives touches lots of low-level details,
they can be decomposed into multiple phases and verified by building 
a stack of layers below $L_\code{PreInit}$.
The verification of these modules 
is left for future work. 

\ignore{Device drivers are not verified
because our current machine semantics lacks device models for
expressing the corresponding semantics.}

Finally, the CompCert assembler for converting assembly into machine
code is also not verified. We also assume the correctness of the Coq
proof checker and its code extraction mechanism.

%The following is no longer accurate: now these switches are fully
%verified.
%% \item some assembly code generated for the switches between ring0
%% and ring3, and between the host and the guest. Our machine
%% semantics % ($\LSem{L}$) models these switches as pseudo
%% primitives. They can be verified if we model more detailed hardware
%% behaviors and instructions in our machine model.
%% C functions, such as memcpy, are not supported by the current 
%% CompCert memory model and thus can not be verified in $\ClightX{L}$.
%% On the other hand, they can be implemented in assembly and verified 
%% at the assembly level, which we leave for future work.
% Do we really have any code in the kernel (I mean, apart from the
% bootloader and preinit) having the following features?
%% \item Some C features are not supported by the current CompCert, e.g.
%% functions with varying number of arguments, and the GCC-style inline
%% assembly. They could be verified in assembly, which we leave for future work.

\paragraph{Expressivity of context code} 
Our assembly machine only covers a small part of the full x86
instruction set and hardware features, so our contextual correctness results only apply to
programs in this subset. Additional instructions 
can be easily added if they have simple or no interaction with our
kernel.  \citet[Section 6]{costanzo16} shows how the fidelity of the
CompCert-style x86 machine model would impact the formal correctness
or security claims, and how such gap can be closed.


\ignore{
\paragraph{Concurrency}
Our current certified kernels assume a runtime environment consisting
of a single processor, but extending it to support multicore
concurrency is already under way. Our choice of using contextual refinement 
to connect layers is motivated partly by its
deep connection with the work on concurrent
objects~\cite{herlihy90,herlihy08book}.

In \CTOS, all primitives introduced at each abstraction layer are
assigned ``atomic'' specifications. Such ``atomicity'' is easy to
establish in the sequential setting when interrupts are turned off.
In the concurrent setting (and even with preemption and all the
interleavings), we would still want the underlying kernel
implementation module to behave like its sequential counterpart 
in all contexts. This is the essence of {\em linearizability}~\cite{herlihy90}.

Recent work on concurrency verification~\cite{liang13,filipovic10} has
shown that contextual refinement is precisely equivalent to
linearizability. In fact, by
varying the observable context and the assumption about the scheduler,
Liang~{\em{}et al}~\cite{liang13} have shown that termination-sensitive
contextual refinement (which we use in \CTOS) is precisely equivalent
to linearizability plus a specific liveness property (i.e., 
wait-freedom, lock-freedom, obstruction-freedom, starvation-freedom
or deadlock-freedom).

These results suggest that by using contextual
refinement, \CTOS\ can isolate and encapsulate fine-grained concurrent
interleavings inside the implementation of each kernel object within a
single layer. Non-blocking fine-grained concurrent data structures can have
very sophisticated local invariants, but they are not exported to
other parts of the kernel. This makes the \CTOS\ architecture much
more appealing and extensible.}

\paragraph{Preemptive interrupt} Like most existing verified kernel efforts,
we do not allow preemptive interrupts inside the kernel. The
challenges in handling preemption are similar to those
for concurrency. 
We plan to model different devices
as virtual CPUs
and utilize the hardware scheduler
to capture the
preemptive interrupts between devices and the kernel.

\paragraph{Storage system}
All our kernels currently lack a certified storage system.
%and a certified network stack.
%The Linux community~\cite{lkmap} sorted these
%into different stacks of abstraction layers (based on their underlying
%hardware devices).\vilhelm{it's not clear to me what point this sentence makes.}
We plan to incorporate recent advances in building
certified file systems~\cite{fscq15,cogent16} into \mCTOS{} and \cCTOS\ in the near future.

\paragraph{Linking across layers before compiling}
In our current framework, all the modules are compiled
 within their own layer interfaces and linked together at the assembly level. Thus, we cannot inline functions across layers and ``getter-setter"
 layers introduce performance overhead.
 
Actually, our layer
calculus does provide ways to first link code at the C level across
layers before compiling. Let $L_3$ be an overlay, $L_1$ be an
underlay, and $L_2$ be an intermediate layer interface. Let us assume that we
split each layer interface $L_i$ into two layer interfaces $L_i^C \oplus
L_i^{\mathrm{Asm}}$ and that we proved $L_{i}^{\mathit{lang}} \vdash_{R_i}
M_i^{\mathit{lang}}: L_{i+1}^{\mathit{lang}}$ for each $i \in \{1,2
\}$ and $\mathit{lang} \in \{ C, \mathrm{Asm} \}$.

Then, on each side, we can do vertical composition and obtain
$L_1^{\mathit{lang}} \vdash_{R_2 \circ R_1} M_1^{\mathit{lang}} \oplus
M_2^{\mathit{lang}} : L_3$. We can then follow the process described
in Section~\ref{sec:linking} with $H = L_3$, $L = L_1$ and
$M^{\mathit{lang}} = M_1^{\mathit{lang}} \oplus M_2^{\mathit{lang}}$, so that we obtain:
\[
L_1 \vdash_{R_2 \circ R_1} \mathrm{CompCertX}(M_1^C \oplus M_2^C) \oplus M_1^{\mathrm{Asm}} \oplus M_2^{\mathrm{Asm}}: L_3
\]
This shows that compiling before linking is possible as soon as
ClightX supports vertical composition with refinement. 
Recall that the soundness proof for the vertical composition rule in Section~\ref{sec:seq:sound}
requires the monotonicity of $\oplus$ and the language semantics $\llbracket - \rrbracket$.
For ClightX,
the
corresponding Coq proof for monotonicity is underway. 
Once it is proved, because CompCertX already
supports function inlining (within a single module) just like CompCert
does, if an intermediate layer interface defining ``getter-setters'' is to be
implemented through simple functions performing only a single memory
access, then compilation before linking will allow suppressing the
function call overhead for these simple functions. 
As they are linked
within a single module before compilation, so that memory accesses
will be inlined in the overlay implementation.



% This part is mostly covered in Section 5 now, we shouldn't need it anymore
\begin{comment}
\paragraph{Security and information flow}
We also plan to utilize the extensible, layered framework of
\CTOS{} to guarantee that information flow or security properties are never
broken by a valid layer implementation. For example, consider proving
a variant of the end-to-end confidentiality property known in the
literature as \emph{noninterference}. Informally, the property says
that the observable behavior of a program is independent of the
initial values of some particular high-security data (i.e., there is
no flow of information from the high-security data to the observable
events produced by the program). We define the specification of a
program as the (partial) mapping from initial state to final state,
and call a specification ``noninterfering'' if it satisfies the
property just described. Our goal is then to prove that, at any layer
$L_i$, if all the primitives implemented in layer $L_{i-1}$ have
noninterfering specifications, then a program written in layer
$L_i$ using those primitives will also be noninterfering. We
have found that such a goal is achievable via instrumentation of the
CompCert-style memory model with security labels, and
intelligently placed label checks within the operational
semantics. Note that these security labels are abstract state---they
do not actually exist in the concrete machine, and thus they do not
add any execution overhead.

We also intend to leverage our \CTOS\ architecture to generalize the
integrity and noninterference properties of seL4~\cite{murray13,sewell11}
beyond the purely access-control-based policy that parameterizes the 
properties. Rather than explicitly storing pieces of an access control 
policy in capabilities and passing them between kernel objects, we wish 
to reason about label-based policies via a purely static instrumented 
machine. Another way to view this goal is with respect to the HiStar 
operating system~\cite{zeldovich06}. In HiStar, all kernel objects have
an attached security label. Label checks are performed during kernel 
execution to prevent undesirable information flows, though no formal 
guarantees regarding information flow are stated or proved. Our goal 
can be viewed, then, as taking HiStar's security labels, migrating them 
from the actual machine into the realm of static verification, and 
proving extensible, end-to-end information-flow guarantees. Through this 
process, we also anticipate that security policies (given through 
specifications) will become clearer and more declarative.
\end{comment}

\ignore{
\paragraph{Evaluation and limitations} 
The planning and development of \mCTOSbase{} took 9.5 person months plus
2 person months on linking and code extraction.
With the infrastructure in place, \mCTOShyper{} only took 1.5 person months
to finish, and \mCTOSringz{} and \mCTOSembed{} take half a person month each.
The kernels are written, layer by layer, in LAsm and ClightX abstract syntaxes
along with driver functions specifying how to compose (link) them.
All of those are in Coq for the proofs to refer to.
We utilize Coq's code extraction to get an OCaml program which contains
CompCertX, the abstract syntax trees of the kernels, and the driver functions,
which invoke CompCertX on pieces of ClightX code and
generate the full assembly file.
The output of the OCaml program is then fed to an assembler to produce
the kernel executable.

With the device drivers (running as user processes) and a cooperative 
scheduler, most of the benchmarks in
lmbench\footnote{\url{http://lmbench.sourceforge.net/}}
are under 2x slowdown running in \mCTOShyper{},
well within expected overhead.
Ring 0 processes, not used in the above experiment, can 
easily lower the number
as we measured one to two orders of magnitude reduction in the number of cycles
needed to serve system calls and context switches.

Because the proof was originally developed directly in terms of
abstract machines and program transformations,
the current code base does not yet reflect the calculus presented in
Sec. \ref{sec:layer} in its entirety.
%The most significant discrepency is that the simulation relations blueprints
%used by our legacy code do not actually compose.%
%\footnote{
%  This is not a fundamental limitation of our approach,
%  but merely a technical difficulty due to the way
%  the compiler's memory injections are integrated to
%  the definition of these relations
%  in our pre-existing code base.
%  % XXX: Please refer to the technical report for more 
%  % complete explanation.
%}
% Expand in technical report:
%  The simulation relations need to factor in the peculiar form of the
%  compiler's correctness theorem
%  (XXX: refer somehow to Sec. \ref{sec:comp.tex}),
%  and consequently are parametrized over Compcert memory injections.
%  In order to define the composition $(R_1 \circ R_2)(j)$ from
%  $R_1(j_1)$ and $R_2(j_2)$,
%  we would need to find a way to split $j$ into $j_1$ and $j_2$
%  XXX: explain more
Notably,
vertical composition is done at the level of
the whole-machine contextual refinements
obtained by applying the soundness theorem
to each individual abstraction layer.
%[XXX: Talk about simulation paths, refactoring to address this issue?]

Outside our verified kernels
(\mCTOShyper{} consists of about 3000 lines of C and assembly), there
are 300 lines of C and 170 lines of x86 assembly code that are not
verified yet: the preinit procedure, the ELF loader used by user
process creation, and functions such as \textsf{memcpy} which currently
cannot be verified because of a limitation arising from the CompCert
memory model. Device drivers are not verified because LAsm
lacks device models for expressing the correctness
statement.  Finally, the CompCert assembler for converting LAsm into
machine code remains unverified. 
%We also assume the correctness of the
%Coq proof checker and its code extraction mechanism.

LAsm does not cover the full x86 instruction sets and many other
hardware features.  This means that our correctness results only apply
to programs in this subset. However, additional instructions and
features can be easily added if they have simple or no interaction
with our kernel.}

